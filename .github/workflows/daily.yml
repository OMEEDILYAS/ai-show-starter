# ------------------------------
# Daily multi-series episode run
# Builds episodes, publishes the final MP4 to gh-pages,
# waits for GitHub Pages to finish building, then:
#   - Posts to Instagram for ai_teacher (REAL)
#   - Dry-runs for other series (NO post)
# ------------------------------

name: daily-episodes

on:
  schedule:
    - cron: "0 15 * * *"   # run daily at 15:00 UTC (10:00 America/Chicago)
  workflow_dispatch:        # allow manual runs

permissions:
  contents: write           # needed to push to gh-pages

jobs:
  episode:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        # We still render all three, but only ai_teacher will post to IG.
        series: [ai_teacher, ai_drama, ai_memes]

    concurrency:
      group: daily-${{ matrix.series }}
      cancel-in-progress: false
    timeout-minutes: 40

    env:
      # Calm, readable fallback background (used by gen_background.py)
      BG_COLOR: "0x101426"
      # Force Card adapter everywhere for watchable visuals (route_shots.py reads this)
      FORCE_CARD: "1"

    steps:
      # --- Repo checkout & tooling setup ---
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('infra/requirements.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      - name: Install Python deps
        # If you maintain infra/requirements.txt, we use it; otherwise install minimal deps.
        run: |
          if [ -f infra/requirements.txt ]; then
            pip install -r infra/requirements.txt
          else
            pip install requests pyyaml pandas openai
          fi

      - name: Install FFmpeg & fonts
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg fonts-dejavu-core
          ffmpeg -version
          ffprobe -version || true

      # --- Pull cached stock from gh-pages into local repo (so visuals have motion even w/o new fetch) ---
      - name: Checkout gh-pages into site/
        uses: actions/checkout@v4
        with:
          ref: gh-pages
          path: site

      - name: Seed local stock library from cache
        run: |
          mkdir -p assets/stock/${{ matrix.series }}
          if [ -d "site/stock/${{ matrix.series }}" ]; then
            rsync -a "site/stock/${{ matrix.series }}/" "assets/stock/${{ matrix.series }}/" || true
          fi
          if [ -d "site/stock/common" ]; then
            mkdir -p assets/stock/common
            rsync -a "site/stock/common/" "assets/stock/common/" || true
          fi

      # --- (Optional) Generate 2–3 simple placeholder stock loops so router never goes blank ---
      - name: Generate placeholder stock (safety net)
        run: |
          mkdir -p assets/stock/ai_teacher
          ffmpeg -y -f lavfi -i "color=c=#202a44:s=1080x1920:d=5" \
            -vf "drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf:text='Vectors':fontsize=96:fontcolor=white:x=w/2-200+50*t:y=h/2-60" \
            assets/stock/ai_teacher/vectors.mp4
          ffmpeg -y -f lavfi -i "color=c=#2a4433:s=1080x1920:d=5" \
            -vf "drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf:text='Patterns':fontsize=80:fontcolor=white:x=w/2-250-40*t:y=h/2" \
            assets/stock/ai_teacher/patterns.mp4 || true

      # --- Plan & write the episode copy (title/overlay/narration) ---
      - name: Plan episode
        run: python planner/plan_next.py --series "${{ matrix.series }}"

      - name: Director agent (title/overlay/narration)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL: gpt-4o
        run: python planner/agent_director.py --series "${{ matrix.series }}"

      - name: Generate assets (voice.wav, title/overlay/narration files)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_TTS_MODEL: gpt-4o-mini-tts
          OPENAI_TTS_VOICE: verse
        run: python generator/gen_assets.py --series "${{ matrix.series }}"

      # --- Fetch & select stock BEFORE routing (so router sees assets/stock_list.txt) ---
      - name: Fetch stock clips (Pexels/Pixabay)
        if: ${{ env.PEXELS_API_KEY != '' || env.PIXABAY_API_KEY != '' }}
        env:
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
          PIXABAY_API_KEY: ${{ secrets.PIXABAY_API_KEY }}
        run: |
          python generator/fetch_stock.py --series "${{ matrix.series }}" --max_new 6 --per_query 8

      - name: Select stock clips (build assets/stock_list.txt)
        run: python generator/select_stock.py --series "${{ matrix.series }}" --max_clips 6

      # --- Push any newly fetched stock back into gh-pages "stock cache" ---
      - name: Push updated stock cache to gh-pages
        run: |
          set -e
          mkdir -p site/stock/${{ matrix.series }}
          shopt -s nullglob
          newfiles=(assets/stock/${{ matrix.series }}/*.mp4)
          if [ ${#newfiles[@]} -gt 0 ]; then
            cp -n assets/stock/${{ matrix.series }}/*.mp4 site/stock/${{ matrix.series }}/ || true
          fi
          if [ -d assets/stock/common ]; then
            mkdir -p site/stock/common
            cp -n assets/stock/common/*.mp4 site/stock/common/ 2>/dev/null || true
          fi
          cd site
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "stock/${{ matrix.series }}" "stock/common" || true
          git commit -m "stock cache update (${{ matrix.series }}) run ${{ github.run_id }}" || echo "nothing to commit"
          git pull --rebase origin gh-pages || true
          git push

      # --- Visual generation: calm background, shotlist, route (Card-first) ---
      - name: Generate background (calm solid color)
        env:
          BG_COLOR: ${{ env.BG_COLOR }}
        run: python generator/gen_background.py --series "${{ matrix.series }}"

      - name: Make shotlist (beats)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL: gpt-4o
        run: python planner/make_shotlist.py --series "${{ matrix.series }}"

      - name: Route beats → shots (Card-first + stock-aware)
        env:
          FORCE_CARD: ${{ env.FORCE_CARD }}   # router_shots.py reads this; ensures Card visuals
        run: python generator/route_shots.py --series "${{ matrix.series }}"

      - name: Build/trim visuals to narration
        run: python assembly/cut_visuals.py --series "${{ matrix.series }}"

      - name: Create subtitles (SRT)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: python generator/make_srt.py --series "${{ matrix.series }}"

      - name: Assemble final video
        run: python assembly/build_video.py --series "${{ matrix.series }}"

      - name: Validate final video (size/codec/duration)
        run: python assembly/validate_video.py --series "${{ matrix.series }}"

      # --- Resolve the final MP4 path and build a caption from title+overlay ---
      - name: Resolve final mp4 & caption
        id: meta
        run: |
          set -e
          series="${{ matrix.series }}"

          # --- Find the latest plan.json (may be empty if something failed earlier) ---
          PLAN=$(ls -t out/"$series"/ep_*/plan.json 2>/dev/null | head -n1 || true)

          # --- Prefer plan["video_path"]; fallback to newest file in out/<series>/final ---
          MP4=""
          if [ -n "$PLAN" ]; then
            MP4=$(
              python - "$PLAN" <<'PY'
import json, sys
from pathlib import Path

p = Path(sys.argv[1])
try:
    plan = json.loads(p.read_text(encoding="utf-8"))
except Exception:
    plan = {}
print(plan.get("video_path",""))
PY
            )
          fi

          if [ -z "$MP4" ] || [ ! -f "$MP4" ]; then
            MP4=$(ls -t out/"$series"/final/*.mp4 2>/dev/null | head -n1 || true)
          fi
          if [ -z "$MP4" ]; then
            echo "No final mp4 found" >&2
            exit 1
          fi

          FILE_BASENAME=$(basename "$MP4")

          # --- Resolve the episode assets directory for caption text ---
          # Prefer the ep dir from PLAN; else pick the latest ep dir under the series.
          if [ -n "$PLAN" ]; then
            EP_DIR=$(dirname "$PLAN")
          else
            EP_DIR=$(ls -d out/"$series"/ep_* 2>/dev/null | sort -r | head -n1 || true)
          fi

          TITLE="${series} Daily"
          OVERLAY="New episode!"
          if [ -n "$EP_DIR" ]; then
            TITLE=$(cat "$EP_DIR/assets/title.txt" 2>/dev/null || echo "${series} Daily")
            OVERLAY=$(cat "$EP_DIR/assets/overlay.txt" 2>/dev/null || echo "New episode!")
          fi

          CAPTION="${TITLE} — ${OVERLAY}"

          # --- Output variables for later steps ---
          {
            echo "mp4=$MP4"
            echo "file=$FILE_BASENAME"
            echo "caption<<EOF"
            echo "$CAPTION"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

      # --- Publish the MP4 into gh-pages (stable, fetchable URL) ---
      - name: Publish MP4 to gh-pages (reels/<series>/<timestamped>.mp4)
        id: publish
        run: |
          set -e
          FILE="${{ steps.meta.outputs.mp4 }}"
          NAME="${{ matrix.series }}-${{ github.run_id }}.mp4"
          mkdir -p site/reels/${{ matrix.series }}
          cp "$FILE" "site/reels/${{ matrix.series }}/$NAME"
          cd site
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "reels/${{ matrix.series }}/$NAME"
          git commit -m "reel: $NAME (${{ matrix.series }}) from run ${{ github.run_id }}" || true
          git pull --rebase origin gh-pages || true
          git push
          echo "name=$NAME" >> "$GITHUB_OUTPUT"

      # --- WAIT for GitHub Pages to finish building the site (not just hope/guess) ---
      - name: Wait for GitHub Pages build (official API)
        id: pages
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          OWNER="${GITHUB_REPOSITORY_OWNER}"
          REPO="${GITHUB_REPOSITORY#*/}"
          # Poll /pages/builds/latest until status == "built" (or timeout)
          for i in {1..90}; do
            RESP=$(curl -sS -H "Authorization: Bearer ${GH_TOKEN}" \
              -H "Accept: application/vnd.github+json" \
              "https://api.github.com/repos/${OWNER}/${REPO}/pages/builds/latest")
            STATUS=$(echo "$RESP" | jq -r '.status // empty')
            echo "[pages] try $i -> status=$STATUS"
            if [ "$STATUS" = "built" ]; then
              echo "ready=true" >> $GITHUB_OUTPUT
              break
            fi
            if [ "$STATUS" = "errored" ]; then
              echo "Pages build errored"; exit 1
            fi
            sleep 2
          done

      # --- Compute the public file URL (project pages path) ---
      - name: Compute public URL
        id: url
        run: |
          OWNER="${GITHUB_REPOSITORY_OWNER}"
          REPO="${GITHUB_REPOSITORY#*/}"
          FILE="${{ steps.publish.outputs.name }}"
          BASE="https://${OWNER}.github.io/${REPO}"
          URL="${BASE}/reels/${{ matrix.series }}/${FILE}"
          echo "url=${URL}" >> $GITHUB_OUTPUT
          echo "Public URL: ${URL}"

      # --- Final sanity check on the actual file URL (HEAD must be 200 + content-type: video/*) ---
      - name: HEAD check wait until file is live
        id: head
        run: |
          set -e
          URL="${{ steps.url.outputs.url }}"
          echo "Waiting for: $URL"
          for i in {1..90}; do
            code=$(curl -sI -o /dev/null -w "%{http_code}" "$URL" || true)
            ctype=$(curl -sI "$URL" | awk -F': ' 'tolower($1)=="content-type"{print tolower($2)}' | tr -d '\r' || true)
            echo "[try $i] code=$code ctype=$ctype"
            if [ "$code" = "200" ] && [[ "$ctype" == video/* ]]; then
              echo "live=true" >> $GITHUB_OUTPUT
              exit 0
            fi
            sleep 2
          done
          echo "live=false" >> $GITHUB_OUTPUT
          exit 0

      # --- Instagram posting rules ---
      # Only ai_teacher posts "for real".
      # Others do a DRY step so you can confirm URL/caption without hitting the IG API.

      - name: Post to Instagram — REAL (ai_teacher only)
        if: ${{ matrix.series == 'ai_teacher' && steps.head.outputs.live == 'true' }}
        env:
          IG_ACCESS_TOKEN: ${{ secrets.IG_ACCESS_TOKEN }}
          IG_USER_ID: ${{ secrets.IG_USER_ID }}
        run: |
          URL="${{ steps.url.outputs.url }}"
          CAP="${{ steps.meta.outputs.caption }}"
          echo "Posting (REAL) for ai_teacher: $URL"
          python publisher/post_instagram.py "$URL" "$CAP"

      - name: Post to Instagram — DRY RUN (all non-ai_teacher)
        if: ${{ matrix.series != 'ai_teacher' && steps.head.outputs.live == 'true' }}
        run: |
          URL="${{ steps.url.outputs.url }}"
          CAP="${{ steps.meta.outputs.caption }}"
          echo "[DRY] Would post for series=${{ matrix.series }}"
          echo "[DRY] URL: $URL"
          echo "[DRY] CAPTION: $CAP"

      # --- Artifacts for inspection ---
      - name: Upload final mp4 artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.series }}-final
          path: out/${{ matrix.series }}/final/*.mp4
