convincing to many. Further, the conceptcan be computationally useful: algorithms that aim to identify ǫ-Nash equilibria need to consider only a finite set of mixedstrategyprofilesratherthanthewholecontinuousspace.(Ofcourse,thesizeofthis finitesetdependsonbothǫandonthegame’spayoffs.)Sincecomputersgenerally representrealnumbersusingafloating-pointapproximation,itisusuallythecase that even methods for the “exact” computation of Nash equilibria (see e.g., Section4.2)actuallyfindonlyǫ-equilibriawhereǫisroughlythe“machineprecision” (ontheorderof10−16 orless formostmoderncomputers). ǫ-Nashequilibriaare alsoimportantto multiagentlearningalgorithms; we discussthem in thatcontext inSection7.3. However, ǫ-Nash equilibria also have several drawbacks. First, although Nash equilibriaarealwayssurroundedbyǫ-Nashequilibria,thereverseisnottrue. Thus, agivenǫ-NashequilibriumisnotnecessarilyclosetoanyNashequilibrium. This underminesthesenseinwhichǫ-NashequilibriacanbeunderstoodasapproximationsofNashequilibria. ConsiderthegameinFigure3.19. L R U 1,1 0,0 D 1+ ǫ,1 500,500 2 Figure3.19: Agamewithaninterestingǫ-Nashequilibrium. This game has a unique Nash equilibrium of (D,R), which can be identified throughthe iterated removalof dominatedstrategies. (D dominatesU for player 1; on the removal of U, R dominates L for player 2.) (D,R) is also an ǫ-Nash equilibrium,ofcourse. However,thereisalsoanotherǫ-Nashequilibrium: (U,L). Thisgameillustratestwothings. First, neither player’s payoff under the ǫ-Nash equilibrium is within ǫ of his payoffinaNashequilibrium;indeed,ingeneralbothplayers’payoffsunderanǫNashequilibriumcanbearbitrarilylessthaninanyNashequilibrium.Theproblem isthattherequirementthatplayer1cannotgainmorethanǫbydeviatingfromthe ǫ-Nash equilibrium strategy profile of(U,L) does not imply that player 2 would notbeabletogainmorethanǫbybestrespondingtoplayer1’sdeviation. Second,someǫ-Nashequilibriamightbeveryunlikelytoariseinplay. Although player1mightnotcareaboutagainof ǫ,hemightreasonthatthefactthatDdom2 inatesU wouldleadplayer2toexpecthimtoplayD,andthatplayer2wouldthus playRinresponse.Player1mightthusplayDbecauseitishisbestresponsetoR. Overall,theideaofǫ-approximationismuchmessierwhenappliedtotheidentifiUncorrectedmanuscriptofMultiagentSystems,publishedbyCambridgeUniversityPress Revision1.1©Shoham&Leyton-Brown,2009,2010. 3.5 Historyandreferences 87 cationofa fixedpointthanwhenit is appliedto a (single-objective)optimization problem. 3.5 Historyandreferences Thereexistseveralexcellenttechnicalintroductorytextbooksforgametheory, includingOsborneand Rubinstein [1994], Fudenbergand Tirole [1991], andMyerson[1991].Thereaderinterestedingainingdeeperinsightintogametheoryshould consultnotonlythese, butalsothe mostrelevantstrands ofthe the vastliterature ongametheorywhichhasevolvedovertheyears. The origins of the material coveredin the chapterare as follows. In 1928, von Neumannderivedthe“maximin”solutionconcepttosolvezero-sumnormal-form games[vonNeumann,1928]. Ourproofofhisminimaxtheoremis similartothe one in Luce and Raiffa [1957b]. In 1944, he together with Oskar Morgenstern authored what was to become the founding document of game theory [von NeumannandMorgenstern,1944];asecondeditionquicklyfollowedin1947.Among the many contributions of this work are the axiomatic foundations for “objective probabilities”and whatbecame knownas von Neumann–Morgensternutility theory. The classical foundation of “subjective probabilities” is Savage [1954], but wedonotcoverthosesincetheydonotplayaroleinthebook. Acomprehensive overviewofthesefoundationaltopicsisprovidedbyKreps[1988],amongothers. OurowntreatmentofutilitytheorydrawsonPooleetal. [1997];seealsoRussell andNorvig[2003]. ButvonNeumannandMorgenstern[1944]didmuchmore;theyintroducedthe normal-form game, the extensive form (to be discussed in Chapter 5), the conceptsofpureandmixedstrategies,aswellasothernotionscentraltogametheory. Schelling [1960] was one of the first to show that interesting social interactions could usefully be modeled using game theory, for which he was recognized in 2005withaNobelPrize. Shortly afterward John Nash introduced the concept of what would become known as the “Nash equilibrium” [Nash, 1950; Nash, 1951], without a doubt the most influential concept in game theory to this date. Indeed, Nash received a Nobel Prize in 1994 because of this work.9 The proof in Nash [1950] uses Kakutani’sfixed-pointtheorem;ourproofofTheorem3.3.22followsNash[1951]. Lemma 3.3.14 is due to Sperner [1928] and Theorem 3.3.17 is due to Brouwer [1912];ourproofofthelatterfollowsBorder[1985]. This workopenedthefloodgatesto aseriesofrefinementsandalternativesolution concepts which continues to this day. We covered several of these solution concepts.TheliteratureonParetooptimalityandsocialoptimizationdatesbackto the early twentieth century, includingseminalwork byPareto and Pigou, butperhapswas bestestablishedby Arrow in his seminalwork onsocialchoice[Arrow, 9. JohnNashwasalsothetopicoftheOscar-winning2001movieABeautifulMind;however, themovie hadlittletodowithhisscientificcontributionsandindeedgotthedefinitionofNashequilibriumwrong. Freeforon-screenuse;pleasedonotdistribute.Youcangetanotherfreecopy ofthisPDFororderthebookathttp://www.masfoundations.org. 88 3 IntroductiontoNoncooperativeGameTheory:GamesinNormalForm 1970]. TheminimaxregretdecisioncriterionwasfirstproposedbySavage[1954], andfurtherdevelopedinLoomesandSugden[1982]andBell[1982].Recentwork from a computerscience perspectiveincludes Hyafil and Boutilier [2004], which alsoappliesthiscriteriontotheBayesiangamessettingweintroduceinSection6.3. Iterated removal of dominated strategies, and the closely related rationalizability, enjoyalonghistory,thoughmoderndiscussionofthemismostfirmlyanchoredin twoindependentandconcurrentpublications:Pearce[1984]andBernheim[1984]. CorrelatedequilibriawereintroducedinAumann[1974];Myerson’squoteistaken fromSolanandVohra[2002]. Trembling-handperfectionwasintroducedinSelten [1975]. Anevenstrongernotionthan(trembling-hand)perfectequilibriumisthat of proper equilibrium [Myerson, 1978]. In Chapter 7 we discuss the concept of evolutionarilystablestrategies[MaynardSmithandPrice,1973]andtheirconnectionto Nashequilibria. In additionto suchsingle-equilibriumconcepts,there are conceptsthatapplytosetsofequilibria,notsingleones. Ofnotearethenotionsof stable stableequilibriaasoriginallydefinedinKohlbergandMertens[1986],andvarious equilibrium laterrefinementssuchashyperstablesetsdefinedinGovindanandWilson[2005a]. Good surveys of many of these concepts can be found in Hillas and Kohlberg hyperstableset [2002]andGovindanandWilson[2005b]. UncorrectedmanuscriptofMultiagentSystems,publishedbyCambridgeUniversityPress Revision1.1©Shoham&Leyton-Brown,2009,2010.