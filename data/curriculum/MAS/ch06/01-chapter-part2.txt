the strategy space of the repeated gameismuchricherthanthestrategyspaceinthestagegame. Certainlyonestrategyintherepeatedgameistoadoptthesamestrategyineachstagegame;clearly, stationary this memoryless strategy, called a stationary strategy, is a behavioral strategy in strategy theextensive-formrepresentationofthe game. Butin general,the action(ormixture ofactions)playedat a stagegamecandependonthe history ofplay thusfar. Sincethisfactplaysaparticularlyimportantroleininfinitelyrepeatedgames,we postponefurther discussion of it to the next section. Indeed, in the finite, known repetitioncase,weencounteragainthephenomenonofbackwardinduction,which we first encounteredwhen we introducedsubgame-perfectequilibria. Recall that intheCentipedegame,discussedinSection5.1.3,theuniqueSPEwastogodown andterminatethegameateverynode. NowconsiderafinitelyrepeatedPrisoner’s Freeforon-screenuse;pleasedonotdistribute.Youcangetanotherfreecopy ofthisPDFororderthebookathttp://www.masfoundations.org. 150 6 RicherRepresentations:BeyondtheNormalandExtensiveForms Dilemma game. Again, it can be argued, in the last round it is a dominant strategy to defect, no matter what happened so far. This is common knowledge, and nochoiceofactioninthe precedingroundswillimpactthe playin thelastround. Thusin thesecond-to-lastroundtooitis a dominantstrategyto defect. Similarly, by induction, it can be argued that the only equilibrium in this case is to always defect. However,asinthecaseoftheCentipedegame,thisargumentisvulnerable tobothempiricalandtheoreticalcriticisms. 6.1.2 Infinitelyrepeatedgames When the infinitely repeated game is transformed into extensive form, the result is an infinite tree. So the payoffs cannot be attached to any terminal nodes, nor cantheybedefinedasthesumofthepayoffsinthestagegames(whichingeneral will be infinite). There are two commonways ofdefining a player’s payoffin an infinitelyrepeatedgametogetaroundthisproblem. Thefirstistheaveragepayoff ofthestagegameinthelimit.2 Definition6.1.1(Averagereward) Givenaninfinitesequenceofpayoffsr(1),r(2),... i i averagereward forplayeri,theaveragerewardofiis k r(j) lim j=1 i . k→∞ P k The future discounted reward to a player at a certain point of the game is the sum of his payoff in the immediate stage game, plus the sum of future rewards discounted by a constant factor. This is a recursive definition, since the future rewardsagaingiveahigherweighttoearlypayoffsthantolaterones. Definition6.1.2(Discountedreward) Givenaninfinitesequenceofpayoffsr(1),r(2),... i i future forplayeri,andadiscountfactorβwith0 β 1,thefuturediscountedreward ≤ ≤ discounted ofiis ∞ βjr(j). j=1 i reward ThePdiscount factor can be interpreted in two ways. First, it can be taken to representthe fact that the agentcares more about his well-being in the nearterm than in the long term. Alternatively, it can be assumedthat the agentcares about the future just as much as he cares about the present, but with some probability thegamewillbestoppedanygivenround;1 β representsthatprobability. The − analysisofthegameisnotaffectedbywhichperspectiveisadopted. Nowletusconsiderstrategyspacesinaninfinitelyrepeatedgame. Inparticular, considertheinfinitelyrepeatedPrisoner’sDilemmagame. Aswediscussed,there aremanystrategiesotherthan stationaryones. One ofthemostfamousis Tit-forTit-for-Tat(TfT) Tat. TfT is the strategy in which the player starts by cooperating and thereafter 2. Theobservantreaderwillnoticeapotentialdifficultyinthisdefinition,sincethelimitmaynotexist.One canextendthedefinitiontocoverthesecasesbyusingthelimsupoperatorinDefinition6.1.1ratherthan lim. UncorrectedmanuscriptofMultiagentSystems,publishedbyCambridgeUniversityPress Revision1.1©Shoham&Leyton-Brown,2009,2010. 6.1 Repeatedgames 151 choosesin roundj +1 the action chosenby the other playerin round j. Beside beingbothsimpleandeasytocompute,thisstrategyisnotoriouslyhardtobeat;it wasthewinnerinseveralrepeatedPrisoner’sDilemmacompetitionsforcomputer programs. Since the space of strategies is so large, a natural question is whether we can characterizeallthe Nashequilibria ofthe repeatedgame. Forexample,ifthe discountfactorislargeenough,bothplayersplayingTfTisaNashequilibrium. But triggerstrategy there is an infinite number of others. For example, consider the trigger strategy. This is a draconianversionofTfT; in the triggerstrategy, a playerstarts bycooperating,butifevertheotherplayerdefectsthenthefirstdefectsforever. Again,for sufficientlylargediscountfactor,thetriggerstrategyformsaNashequilibriumnot onlywithitselfbutalsowithTfT. The folk theorem—so-called because it was part of the common lore before it was formally written down—helpsus understandthe space of all Nash equilibria of an infinitely repeated game, by answering a related question. It does not characterize the equilibrium strategy profiles, but rather the payoffs obtained in them. Roughly speaking, it states that in an infinitely repeated game the set of average rewardsattainablein equilibriumarepreciselythosepairsattainableundermixed strategies in a single-stage game, with the constraint on the mixed strategies that each player’s payoff is at least the amount he would receive if the other players adoptedminmaxstrategiesagainsthim. More formally, consider any n-player game G =