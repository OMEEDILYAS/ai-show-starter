Revision1.1©Shoham&Leyton-Brown,2009,2010. 6.2 Stochasticgames 159 two, the problem of computing the best response is in the class P. The following resultshowsthatwhentheautomataunderconsiderationareinsteadbounded,the problembecomesNP-complete. Theorem6.1.13 Given a machine game GM = ( 1,2 , ,G) of the limit av- { } M erageinfinitelyrepeatedPrisoner’sDilemma gameG, anautomatonM , andan 2 integer k, the problem of computing a best-responseautomaton M for player 1, 1 suchthats(M ) k,isNP-complete. 1 ≤ FromfiniteautomatatoTuringmachines Turingmachinesaremorepowerfulthanfinite-stateautomataduetotheirinfinite memories. Onemightexpectthatinthisrichermodel,unlikewithfiniteautomata, game-theoreticresults will be preserved. But they are not. For example, there is strong evidence (if not yet proof) that a Prisoner’s Dilemma game of two Turing machines can have equilibria that are arbitrarily close to the repeated C payoff. Thus cooperative play can be approximated in equilibrium even if the machines memorizetheentirehistoryofthegameandarecapableofcountingthenumberof repetitions. The problem of computing a best response yields another unintuitive result. Even if we restrict the opponentto strategies for which the best-response Turing machine is computable, the general problem of finding the best response for any suchinputis notTuringcomputablewhenthediscountfactoris sufficientlyclose toone. Theorem6.1.14 Forthediscounted,infinitely-repeatedPrisoner’sDilemmagame G, there exists a discount factor β > 0 such that for any rational discount factor β (β,1) there is no Turing-computable procedure for computing a best ∈ responsetoastrategydrawnfromthesetofallcomputablestrategiesthatadmita computablebestresponse. Finally, evenbeforeworryingaboutcomputingabestresponse,thereis amore basic challenge: the best response to a Turing machine may not be a Turing machine! Theorem6.1.15 Forthediscounted,infinitely-repeatedPrisoner’sDilemmagame G, thereexists adiscountfactorβ > 0suchthatfor anyrationaldiscountfactor β (β,1) there exists an equilibrium profile (s ,s ) such that s can be imple1 2 2 ∈ mentedbyaTuringmachine,butnobestresponsetos canbeimplementedbya 2 Turingmachine. 6.2 Stochasticgames Intuitively speaking,a stochastic game is a collectionof normal-form games; the agentsrepeatedlyplaygamesfromthiscollection,andtheparticulargameplayed Freeforon-screenuse;pleasedonotdistribute.Youcangetanotherfreecopy ofthisPDFororderthebookathttp://www.masfoundations.org. 160 6 RicherRepresentations:BeyondtheNormalandExtensiveForms at any given iteration depends probabilistically on the previous game played and ontheactionstakenbyallagentsinthatgame. 6.2.1 Definition Stochastic games are very broad framework, generalizing both Markov decision processes (MDPs; see Appendix C) and repeated games. An MDP is simply a stochasticgamewithonlyoneplayer,whilearepeatedgameis astochasticgame inwhichthereisonlyonestagegame. stochasticgame Definition6.2.1(Stochasticgame) A stochastic game (also known as a Markov game)isatuple(Q,N,A,P,r),where: Markovgame • Qisafinitesetofgames; • N isafinitesetofnplayers; • A = A A ,whereA isafinitesetofactionsavailabletoplayeri; 1 n i ×···× • P : Q A Q [0,1] isthe transitionprobabilityfunction; P(q,a,qˆ)is × × 7→ theprobabilityoftransitioningfromstateqtostateqˆafteractionprofilea;and • R = r ,...,r , wherer : Q A Risareal-valuedpayofffunctionfor 1 n i × 7→ playeri. In this definition we have assumed that the strategy space of the agents is the same in all games, and thus that the difference between the games is only in the payofffunction. Removingthis assumptionaddsnotation,butotherwisepresents no major difficulty or insights. Restricting Q and each A to be finite is a subi stantiverestriction, butwe dosofora reason;theinfinite caseraisesanumberof complicationsthatwewishtoavoid. We have specified the payoff of a player at each stage game (or in each state), butnothowthesepayoffsareaggregatedintoanoverallpayoff. Tosolvethisproblem, we can use solutions already discussed earlier in connection with infinitely repeatedgames(Section6.1.2). Specifically, thetwomostcommonlyusedaggregationmethodsareaveragerewardandfuturediscountedreward. 6.2.2 Strategiesandequilibria Wenowdefinethestrategyspaceofanagent.Leth = (q0,a0,q1,a1,...,at−1,qt) t denoteahistoryoftstagesofastochasticgame,andletH bethesetofallpossible t historiesofthislength. ThesetofdeterministicstrategiesistheCartesianproduct A , which requiresa choicefor eachpossiblehistory at eachpointin time. t,Ht i Asinthepreviousgameforms,anagent’sstrategycanconsistofanymixtureover Q deterministicstrategies. However,thereareseveralrestricted classesofstrategies that are of interest, and they form the following hierarchy. The first restriction is therequirementthatthemixingtakeplaceateachhistoryindependently;thisisthe restrictiontobehavioralstrategiesseeninconnectionwithextensive-formgames. UncorrectedmanuscriptofMultiagentSystems,publishedbyCambridgeUniversityPress Revision1.1©Shoham&Leyton-Brown,2009,2010. 6.2 Stochasticgames 161 Definition6.2.2(Behavioralstrategy) A behavioral strategy s