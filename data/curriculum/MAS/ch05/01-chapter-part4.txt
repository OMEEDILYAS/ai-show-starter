to the nonterminal nodes H. The players’ equilibrium strategies follow straightforwardlyfrom this extendedutility function: everytime a givenplayer i hasthe opportunitytoactatagivennodeh H (i.e.,ρ(h) = i), thatplayerwillchoose ∈ anactiona χ(h)thatsolvesargmax u (σ(a ,h)). Thesestrategiescan i ∈ ai∈χ(h) i i alsobereturnedbyBACKWARDINDUCTION givensomeextrabookkeeping. While the proceduredemonstratesthat in principle a sample SPE is effectively computable, in practice many game trees are not enumerated in advance and are henceunavailableforbackwardinduction. Forexample,theextensive-formrepresentation of chess has around 10150 nodes, which is vastly too large to represent explicitly. Forsuchgamesitismorecommontodiscussthesizeofthegametree in terms of the average branching factor b (the average number of actions which are possible at each node) and a maximum depth m (the maximum number of sequentialactions). AprocedurewhichrequirestimelinearinthesizeoftherepresentationthusexpandsO(bm)nodes. Unfortunately,wecandonobetterthanthis onarbitraryperfect-informationgames. Two-player,zero-sumgames:minimaxandalpha-betapruning We can makesome computationalheadwayin the widely applicablecase of twoplayer, zero-sum games. We first note that BACKWARDINDUCTION has another minimax namein the two-player,zero-sum context: the minimax algorithm. Recall thatin algorithm suchgames,onlyasinglepayoffnumberis requiredto characterizeanyoutcome. Player1 wants to maximizethis number,while player2 wants to minimize it. In this context BACKWARDINDUCTION can be understoodas propagatingthese singlepayoffnumbersfromtheleavesofthetreeuptotheroot. Eachdecisionnode for player 1 is labeled with the maximum of the labels of its child nodes (representing the fact that player 1 would choose the corresponding action), and each decision node for player 2 is labeled with the minimum of that node’s children’s labels. The label on the root node is the value of the game: player 1’s payoff in equilibrium. How can we improve on the minimax algorithm? The fact that player 1 and pruning player 2 always have strictly opposing interests means that we can prune away some parts of the game tree: we can recognize that certain subtrees will never be reached in equilibrium, even without examining the nodes in these subtrees. Thisleadsustoanewalgorithmcalled ALPHABETAPRUNING, whichisgivenin Figure5.7. There are several ways in which ALPHABETAPRUNING differs from BACKWARDINDUCTION. Someconcernthefactthatwehavenowrestrictedourselvesto asetting wherethereareonlytwo players,andoneplayer’sutility is the negative oftheother’s. Wethusdealonlywiththeutilityforplayer1. Thisiswhywetreat thetwoplayersseparately,maximizingforplayer1andminimizingforplayer2. At each node h either α or β is updated. These variablestake the value ofthe Freeforon-screenuse;pleasedonotdistribute.Youcangetanotherfreecopy ofthisPDFororderthebookathttp://www.masfoundations.org. 126 5 GameswithSequentialActions:ReasoningandComputingwiththeExtensiveForm functionALPHABETAPRUNING (nodeh,realα,realβ)returnsu (h) 1 ifh Z then ∈ returnu (h) //hisaterminalnode 1 best_util (2ρ(h) 3) //−∞forplayer1;∞forplayer2 ← − ×∞ foralla χ(h)do ∈ ifρ(h) = 1then best_util max(best_util,ALPHABETAPRUNING(σ(h,a),α,β)) ← ifbest_util β then ≥ returnbest_util α max(α,best_util) ← else best_util min(best_util,ALPHABETAPRUNING(σ(h,a),α,β)) ← ifbest_util αthen ≤ returnbest_util β min(β,best_util) ← returnbest_util Figure 5.7: The alpha-betapruningalgorithm. It is invokedat the rootnodeh as ALPHABETAPRUNING(h, , ). −∞ ∞ previously encountered node that their corresponding player (player 1 for α and player2 for β) would mostprefer to chooseinstead of h. For example, consider the variableβ atsomenodeh. Now considerall the differentchoicesthat player 2couldmakeatancestorsofhthatwouldpreventhfromeverbeingreached,and thatwouldultimatelyleadtopreviouslyencounteredterminalnodes. β isthebest valuethatplayer2couldobtainatanyoftheseterminalnodes.Becausetheplayers donothaveanyalternativetostartingattherootofthetree,atthebeginningofthe searchα = andβ = . −∞ ∞ We can now concentrate on the important difference between BACKWARDINDUCTIONandALPHABETAPRUNING: inthelatterprocedure,thesearchcanbacktrackatanodethatisnotterminal. Letusthinkaboutthingsfromthepointofview ofplayer1, who is consideringwhataction to play atnode h. (As we encourage you to check for yourself, a similar argument holds when it is player 2’s turn to moveatnodeh.) For player1, this backtrackingoccurson the line thatreads “if best_util β then return best_util.” What is going on here? We have just ex- ≥ ploredsome,butnotall,ofthechildrenofplayer1’sdecisionnodeh;thehighest valueamongthese explorednodesis best_util. The valueofnodeh