| onlyifM,w′ = ϕforeverysequenceofpossibleworlds(w = w ,w ,...,w = 0 1 n | w′) for which the following holds: for every 0 i < n there exists an agent ≤ j Gsuchthatw I (w ). i+1 j i ∈ ∈ Second, it is worth noting that our S5 axiomatic system can also be enriched toprovidea soundandcompleteaxiomatizationof C . Itturnsoutthatwhatare G neededaretwoadditionalaxiomsandonenewinferencerule. Axiom13.4.4(A3) E ϕ K ϕ G ↔ i∈G i Axiom13.4.5(A4) C ϕ EV (ϕ C ϕ) G G G → ∧ Rule13.4.6(R3) Fromϕ E (ψ ϕ)inferϕ C ψ G G → ∧ → Thislastinferenceruleisaformofaninductionrule. Armedwiththisnotionofcommonknowledge,wereturntoourwarringgenerals. Itturnsoutthat,inaprecisesense,wheneveranycommunicationprotocolguarantees a coordinated attack in a particular history, in that history it must achieve commonknowledgebetweenthetwogeneralsthatanattackisabouttohappen. It isnothardtoseethatnofiniteexchangeofacknowledgmentswilleverleadtosuch commonknowledge. Andthusitfollowsthatthereisnocommunicationprotocol that solves the Coordinated Attack problem, at least not as the problem is stated here. 13.5 Doingtime, and anapplicationto robotics We now move to another application of reasoning about knowledge, in robotics. Thedomainofroboticsischaracterizedbyuncertainty;arobotreceivesuncertain readingsfrom its inputdevices, and its motorcontrols produceimprecisemotion. Suchuncertaintyisnotnecessarilytheendoftheworld,solongasitsmagnitudeis nottoolargeforthetaskathand,andthattherobotcanreasonaboutiteffectively. We will explicitly consider the task of robot motion planning under uncertainty, and in particular the question of how a robot knows to stop despite having an imprecise sensor and perhaps also motion controller. We first discuss the singlerobotcase, wherewe see thepowerofthe knowledgeabstraction. We thenmove tothemultiagentcase,whereweshowtheimportanceofeachagentbeingableto modeltheotheragentsinthesystem. 13.5.1 Terminationconditionsformotionplanning Imagine a pointrobotmoving in one dimensionalong the positive reals from the origintotheright,withtheintentionofreachingtheinterval[2,4],thegoalregion (see Figure 13.4). The robot is moving at a fixed finite velocity, so there is no Freeforon-screenuse;pleasedonotdistribute.Youcangetanotherfreecopy ofthisPDFororderthebookathttp://www.masfoundations.org. 424 13 LogicsofKnowledgeandBelief question about whether it will reach the destination; the question is whether the robot will know when to stop. Assume the robot has a position sensor that is inaccurate; if the true position is L, the sensor will return any value in the interval [L 1,L+1]. Weassumethattimeiscontinuousandthatthesensorprovidesread- − ings continuously, butthat the reading valuesare notnecessarilycontinuous. We are looking for a termination condition—a predicate on the readings such that as soonasitevaluatesto“true”therobotwillstop. Whatisareasonabletermination condition? Goal Area Initial State 0 1 2 3 4 5 6 Figure13.4: Aone-dimensionalrobotmotionproblem Consider the termination condition “R = 3” where R is the current reading. This is a “safe” condition, in the sense that if that is the readingthen the robotis guaranteed to be in the goal region. The problem is that, because of the discontinuity of reading values, the robot may never get that reading. In other words, this termination condition is sound but not complete. Conversely, the condition “2 R 4” is complete butnot sound. Is there a soundand completetermina- ≤ ≤ tioncondition? On reflection it is not hard to see that “R 3” is such a condition. Although ≥ therearelocationsoutsidethegoalregionthatcangiverisetoreadingsthatsatisfy the predicate (e.g., in location 10 the reading necessarily does), what matters is the first time the robotencountersthatreading. Givenits starting locationand its motiontrajectory,thefirsttimecanbenoearlierthan2andnolaterthan4. Let us now turn to a slightly more complex, two-dimensional robotic motion planningproblem, depictedin Figure 13.5. A point robotis givena commandto moveinacertaindirection,anditsgoalistoarriveatthedepictedrectangulargoal region. As in the previous example, its sensoris error prone; it returns a reading that is within ρ from the true location (i.e., the uncertainty is captured by a disk