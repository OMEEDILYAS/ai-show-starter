s, u(s,s) = u(s′,s) and 6 u(s,s′) > u(s′,s′). The equality condition is true of any mixed strategy equilibrium with full support, so follows directly. To demonstrate that the inequality holds,itissufficienttofindthes′—orequivalently,theprobabilityofplayingH— that minimizes f(s′) = u(s,s′) u(s′,s′). Expandingf(s′) we see that it is a − quadraticequationwiththe(unique)maximums′ = s,provingourresult. ThisconnectionbetweenanESSandaNashequilibriumisnotaccidental. The followingtwotheoremscapturethisconnection. Theorem7.7.11 Givenasymmetrictwo-playernormal-formgameG =( 1,2 ,A,u) { } andamixedstrategys,ifsisanevolutionarilystablestrategythen(s,s)isaNash equilibriumofG. Thisiseasytoshow. NotethatbydefinitionanESSsmustsatisfy u(s,s) u(s′,s). ≥ Inotherwords,itis abestresponsetoitselfandthusmustbeaNashequilibrium. However,not everyNash equilibrium is an ESS; this property is guaranteedonly forstrictequilibria. Theorem7.7.12 Givenasymmetrictwo-playernormal-formgameG =( 1,2 ,A,u) { } andamixedstrategys,if(s,s)isastrict(symmetric)NashequilibriumofG,then sisanevolutionarilystablestrategy. Thisisalsoeasytoshow. NotethatforanystrictNashequilibriumsitmustbe thecasethat u(s,s)> u(s′,s). ButthissatisfiesthefirstcriterionofanESS. TheESSalsoisrelatedtotheideaofstabilityinthereplicatordynamic. Theorem7.7.13 Givenasymmetrictwo-playernormal-formgameG =( 1,2 ,A,u) { } andamixedstrategys,ifsisanevolutionarilystablestrategythenitisanasymptoticallystablesteadystateofthereplicatordynamicofG. Intuitively,ifastateisanESSthenweknowthatitwillberesistanttoinvasions byotherstrategies. Thus,whenthis strategyis representedbyapopulationinthe replicatordynamic,it will beresistantto smallperturbations. Whatis interesting, however,isthattheconverseisnottrue. Thereasonforthisisthatinthereplicator dynamic, only pure strategies can be inherited. Thus some states that are asymptoticallystablewouldactuallynotberesistanttoinvasionbyamixedstrategy,and thusnotanESS. 7.7.3 Agent-basedsimulationandemergentconventions It was mentioned in Section 7.7.1 that, while motivated by a notion of dynamic processwithin a population, in fact the replicatordynamiconly models the gross UncorrectedmanuscriptofMultiagentSystems,publishedbyCambridgeUniversityPress Revision1.1©Shoham&Leyton-Brown,2009,2010. 7.7 Evolutionarylearningandotherlarge-populationmodels 231 statisticsoftheprocess,notitsdetails.Thereareotherlarge-populationmodelsthat provideamorefine-grainedmodeloftheprocess,with manyparametersthatcan impactthedynamics. Wecallsuchmodels,whichexplicitlymodeltheindividual agent-based agents,agent-basedsimulationmodels. simulation In this we lookatonesuchmodel, gearedtowardthe investigationofhow conventionsemergeinasociety. InSection2.4wesawhowinanyrealisticmultiagent sociallaw systemitiscrucialthattheagentsagreeoncertainsociallaws,inordertodecrease conflictsamongthemandpromotecooperativebehavior. Withoutsuchlawseven thesimplestgoalsmightbecomeunattainablebyanyoftheagents,oratleastnot efficientlyattainable(justimaginedrivingintheabsenceoftrafficrules). Asocial lawrestricts theoptionsavailableto eachagent. A specialcaseofsociallaws are social social conventions, which limit the agents to exactly one option from the many convention available ones (e.g., always driving on the right side of the road). A good social laworconventionstrikesabalancebetweenontheonehandallowingagentssufficientfreedomtoachievetheirgoals,andontheotherhandrestrictingthemsothat theydonotinterferetoomuchwithoneanother. In Section 2.4 we asked how social laws and conventions can be designed by a social designer, but here we ask how such conventions can emerge organically. Roughlyspeaking,the processwe aim to study is one in which individualagents occasionallyinteractwithoneanother,andasaresultgainsomenewinformation. Based on his personalaccumulated information, each agent updates his behavior overtime. Thisprocessisreminiscentofthereplicatordynamic,buttherearecrucialdifferences.Westartinthesameway,andrestrictthediscussiontosymmetric, two-player-two-choicesgames. Here too one can look at much more general settings,butwewillrestrictourselvestothegameschemainFigure7.11. A B A x,x u,v B v,u y,y Figure7.11:Agameforagent-basedsimulationmodels. However,unlikethereplicatordynamic,hereweassumeadiscreteprocess,and furthermoreassumethatateachstageexactlyonepairofagents—selectedatrandomfromthepopulation—play.Thiscontrastssharplywiththereplicatordynamic, whichcanbeinterpretedasimplicitlyassumingthatalmostallpairsofagentsplay beforeupdatingtheirchoicesofaction. Inthisdiscretemodeleachagentistracked individually,andindeeddifferentagentsenduppossessingverydifferentinformation. Freeforon-screenuse;pleasedonotdistribute.Youcangetanotherfreecopy ofthisPDFororderthebookathttp://www.masfoundations.org. 232 7 LearningandTeaching Most importantly, in contrast with the replicator dynamic, the evolution of the systemis notdefinedby someglobalstatistics ofthe system. Instead,eachagent decideshowtoplaythenextgamebasedonhisindividualaccumulatedexperience thusfar. Therearetwoconstraintsweimposeonsuchrules. anonymous Property7.7.14(Anonymity) Theselectionfunctioncannotbebasedontheidenlearningrule titiesofagentsorthenamesofactions. locallearning Property7.7.15(Locality) Theselectionfunctionispurelyafunctionoftheagent’s rule personalhistory;inparticular,itisnotafunctionofglobalsystemproperties. The requirementof anonymity deservessome discussion. We are interested in how social conventionsemerge when we cannot anticipate in advance the games that will be played. For example, if we know that the coordination problem will bethatofdecidingwhethertodriveontheleftoftheroadorontheright,wecan verywellusethenames“left”and“right”intheaction-selectionrule;inparticular, we can admit the trivial updaterule that has all agents drive on the right immediately. Instead, the type of coordination problem we are concerned with is better typifiedbythefollowingexample. Considera collectionofmanufacturingrobots thathavebeenoperatingataplantforfiveyears,atwhichtimeanewcollectionof partsarrivethatmustbeassembled. Theassemblyrequiresusingoneoftwoavailableattachmentwidgets, whichwereintroducedthreeyearsago(andhencewere unknownto the designerof the robots five years ago). Either of the widgets will do,butiftworobotsusedifferentonesthentheyincurthehighcostofconversion whenitis timeforthemto matetheirrespectiveparts. Ourgoalis thattherobots learnto usethe same kind ofwidget. The pointto emphasizeaboutthis example isthatfiveyearsagothedesignercouldhavestatedrulesofthegeneralform“ifin thefutureyouhaveseveralchoices,eachofwhichhasbeentriedthismanytimes andhasyieldedthismuchpayoff,thennexttime makethefollowingchoice”;the designercouldnot,however,havereferredtothespecificchoicesofwidget,since thosewereonlyinventedtwoyearslater. The prohibition on using agent identities in the rules (e.g., “if you see Robot 17 use a widget of a certain type then do the same, but if you see Robot 5 do it thennevermind”)is similarlymotivated. Inadynamicsocietyagentsappearand disappear, denying the designer the ability to anticipate membership in advance. One can sometimes refer to the roles of agents (such as Head Robot), and have them