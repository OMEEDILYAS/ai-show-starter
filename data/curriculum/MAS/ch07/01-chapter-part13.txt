θ˙ (a) = t a′∈A t − t a′∈A t = θ (a)[u (a) u∗]. t (cid:2) P a′∈ (cid:3) A ϕ(cid:2)t (a′) 2 P (cid:3) t t − t (cid:2)P (cid:3) Freeforon-screenuse;pleasedonotdistribute.Youcangetanotherfreecopy ofthisPDFororderthebookathttp://www.masfoundations.org. 226 7 LearningandTeaching The system we have defined has a very intuitive quality. If an action does better than the populationaveragethen the proportionof the populationplayingthis actionincreases,andviceversa. Notethatevenanactionthatisnotabestresponse tothecurrentpopulationstatecangrowasaproportionofthepopulationwhenits expectedpayoffisbetterthanthepopulationaverage. Howshouldweinterpretthisevolutionarymodel? Astraightforwardinterpretationisthatitdescribesagentsrepeatedlyinteractingandreplicatingwithinalarge population. However, we can also interpret the fraction of agents playing a certainstrategyasthemixedstrategyofasingleagent,andtheprocessasthatoftwo identicalagentsrepeatedlyupdatingtheiridenticalmixedstrategiesbasedontheir previousinteraction. Seen in this light, exceptforits continuous-timenature, the evolutionarymodelisnotasdifferentfromtherepeated-gamemodelasitseemsat firstglance. We wouldlike to examinetheequilibriumpointsin this system. Beforewe do, weneedadefinitionofstability. steadystate Definition7.7.2(Steadystate) Asteadystateofapopulationusingthereplicator dynamicisapopulationstateθsuchthatforalla A,θ˙(a) = 0. ∈ In other words, a steady state is a state in which the population shares of each actionareconstant. Thisstabilityconcepthasamajorflaw. Anystateinwhichall playersplaythesameactionisasteadystate. Thepopulationsharesoftheactions willremainconstantbecausethereplicatordynamicdoesnotallowthe“entry”of strategiesthatarenotalreadybeingplayed. Todisallowthesestates,wewilloften requirethatoursteadystatesarestable. Definition7.7.3(Stablesteadystate) Asteadystateθ ofareplicatordynamicis stablesteady stable if there exists an ǫ > 0 such that for every ǫ-neighborhood U of θ there state exists another neighborhood U′ of θ such that if θ U′ then θ U for all 0 t ∈ ∈ t > 0. Thatis,ifthesystemstartscloseenoughtothesteadystate,itremainsnearby. Finally, we might like to define an equilibrium state which, if perturbed, will eventuallyreturnbacktothestate. Wecallthisasymptoticstability. Definition7.7.4(Asymptoticallystablestate) Asteadystateθofareplicatordyasymptotically namicisasymptoticallystableifitisstable,andinadditionthereexistsanǫ > 0 stablestate such that for every ǫ-neighborhood U of θ it is the case that if θ U then 0 ∈ lim θ = θ. t→∞ t The followingexampleillustrates someofthese concepts. Considera homogeneouspopulationplayingtheAnti-Coordinationgame,repeatedinFigure7.9. The game has two pure-strategy Nash equilibria, (A,B) and (B,A), and one mixed-strategyequilibriuminwhichbothplayersselectactionsfromthe distribution(0.5,0.5). Becauseofthesymmetricnatureofthesetting,thereisnowayfor the replicatordynamicto convergeto the pure-strategyequilibria. However,note UncorrectedmanuscriptofMultiagentSystems,publishedbyCambridgeUniversityPress Revision1.1©Shoham&Leyton-Brown,2009,2010. 7.7 Evolutionarylearningandotherlarge-populationmodels 227 A B A 0,0 1,1 B 1,1 0,0 Figure7.9: TheAnti-Coordinationgame. that the state corresponding to the mixed-strategy equilibrium is a steady state, becausewhenhalfoftheplayersareplayingAandhalfareplayingB,bothstrategies have equal expected payoff (0.5) and the population shares of each are constant. Moreover,noticethatthisstateisalsoasymptoticallystable. Thereplicator dynamic,whenstartedinanyotherstateofthepopulation(wheretheshareofplayers playing A is more or less than 0.5) will convergeback to the state (0.5,0.5). Moreformallywecanexpressthisas θ˙(A) = θ(A)(1 θ(A) 2θ(A)(1 θ(A))) − − − = θ(A)(1 3θ(A)+2θ(A)2). − This expression is positive for θ(A) < 0.5, exactly 0 at 0.5, and negative for θ(A)> 0.5,implyingthatthestate(0.5,0.5)isasymptoticallystable. This example suggests that there may be a special relationship between Nash equilibria and states in the replicator dynamic. Indeed, this is the case, as the followingresultsindicate. Theorem7.7.5 Givenanormal-formgameG = ( 1,2 ,A = a ,...,a ,u), 1 k { } { } ifthestrategyprofile(s,s)isa(symmetric)mixedstrategyNashequilibriumofG then the population share vector θ = (s(a ),...,s(a )) is a steady state of the 1 k replicatordynamicofG. Inotherwords,everysymmetricNashequilibriumisasteadystate. Thereason for this is quite simple. In a state corresponding to a mixed Nash equilibrium, allstrategiesbeingplayedhavethesameaveragepayoff,sothepopulationshares remainconstant. As mentioned above, however, it is not the case that every steady state of the replicator dynamic is a Nash equilibrium. In particular, states in which not all actions are played may be steady states because the replicator dynamic cannot introducenewactions, evenwhenthe correspondingmixed-strategyprofileis not a Nash equilibrium. On the other hand, the relationship between Nash equilibria andstablesteadystatesismuchtighter. Theorem7.7.6 Givenanormal-formgameG = ( 1,2 ,A a ,...,a ,u)and 1 k { } { } a mixed strategy s, if the population share