rule is calledfictitiousplay. Repeated games are not the only context in which learning takes place. Certainlythemoregeneralcategoryofstochasticgames(alsodiscussedinChapter6) is also oneinwhich regularityacrosstime allows meaningfuldiscussionoflearning. Indeed,mostofthetechniquesdiscussedinthecontextofrepeatedgamesare applicablemoregenerallytostochasticgames,thoughspecificresultsobtainedfor repeatedgamesdonotalwaysgeneralize. In both cases—repeated and stochastic games—there are additional aspects of the settings worth discussing. These have to do with whether the (e.g., repeated) gameis commonlyknownby the players. If it is, any “learning”that takes place is only aboutthe strategies employedby the other. If the gameis not known,the agent can in addition learn about the structure of the game itself. For example, ina stochasticgamesetting, theagentmaystartoutnotknowingthepayofffunctionsatagivenstagegameorthetransitionprobabilities,butlearnthoseovertime in the course of playing the game. It is most interesting to consider the case in which the game being played is unknown; in this case there is a genuine process of discoverygoing on. (Such a setting could be modeledas a Bayesian game, as describedinSection6.3,thoughtheformalmodelingdetailsarenotnecessaryfor thediscussioninthischapter.)Someoftheremarkableresultsarethat,withcertain Freeforon-screenuse;pleasedonotdistribute.Youcangetanotherfreecopy ofthisPDFororderthebookathttp://www.masfoundations.org. 202 7 LearningandTeaching Yield Dare Yield 2,2 1,3 Dare 3,1 0,0 Figure7.3: ThegameofChicken. learningstrategies, agentscansometimesconvergeto anequilibriumofthe game evenwithoutknowingthe game beingplayed. Additionally, there is the question observability ofwhetherthegameisobservable;dotheplayersseeeachothers’actions,and/or each others’ payoffs? (Of course, in the case of a known game, the actions also revealthepayoffs.) Whilerepeatedandstochasticgamesconstitutethemainsettinginwhichwewill investigatelearning,thereareothersettingsaswell. Chiefamongthemaremodels of large populations. These models, which were largely inspired by evolutionary modelsin biology, are superficiallyquite differentfrom the settingofrepeatedor stochasticgames. Unlikethe latter, whichinvolvea smallnumberofplayers, the evolutionary models consist of a large number of players, who repeatedly play a given game among themselves (e.g., pairwise in the case of two-player games). A closerlook, however,showsthat these models are in factclosely related to the modelsofrepeatedgames.Wediscussthisfurtherinthelastsectionofthischapter. 7.1.3 Iflearningistheanswer,whatisthequestion? Itisveryimportanttobeclearonwhywestudylearninginmultiagentsystems,and how we judge whether a given learning theory is successfulor not. These might seemliketrivialquestions,butinfacttheanswersarenotobvious,andnotunique. First, notethatinthefollowing,whenwespeakaboutlearningstrategies,these should be understood as complete strategies, which involve learning in the sense of choosing action as well as updating beliefs. One consequenceis that learning inthesenseof“accumulatedknowledge"is notalwaysbeneficial. Intheabstract, accumulatingknowledgeneverhurts, since one can always ignorewhat has been learned. But when one precommits to a particularstrategy for acting on accumulatedknowledge,sometimeslessismore. This point is related to the inseparability of learning from teaching, discussed earlier. For example, consider a protagonist agent planning to play an infinitely Chickengame repeatedgameofChicken,depictedinFigure7.3. Inthepresenceofanyopponent whoattemptstolearntheprotagonistagent’sstrategyandplayabestresponse,an optimalstrategyistoplaythestationarypolicyofalwaysdaring;thisisthe“watch out: I’mcrazy”policy. Theopponentwilllearntoalwaysyield,aworseoutcome UncorrectedmanuscriptofMultiagentSystems,publishedbyCambridgeUniversityPress Revision1.1©Shoham&Leyton-Brown,2009,2010. 7.1 Whythesubjectof“learning”iscomplex 203 forhimthanneverlearninganything.3 Broadlyspeaking,wecandividetheoriesoflearninginmultiagentsystemsinto descriptive twocategories—descriptivetheoriesandprescriptivetheories. theory Descriptivetheories prescriptive theory Descriptive theories attempt to study the way learning takes place in real life— usuallybypeople,butsometimesbyotherentitiessuchasorganizationsoranimal species. The goalhereis to showexperimentallythata certain modeloflearning agrees with behavior (typically, in laboratory experiments) and then to identify interestingpropertiesoftheformalmodel. Theidealdescriptivetheorywouldhavetwoproperties. realism Property7.1.1(Realism) Thereshouldbea goodmatchbetweenthe formaltheoryandthenaturalphenomenonbeingstudied. convergence Property7.1.2(Convergence) The formal theory should exhibit interesting behavioralproperties,inparticularconvergenceofthestrategyprofilebeingplayed tosomesolutionconcept(e.g.,equilibrium)ofthegamebeingplayed. One approachto demonstrating realism is to apply the experimentalmethodology of the social sciences. While we will not focus on this approach, there are severalgoodexamplesofitineconomicsandgametheory. Buttherecanbeother reasonsforstudyingagivenlearningprocess. Forexample,totheextentthatone acceptstheBayesianmodelasatleastanidealizedmodelofhumandecisionmaking,thismodelprovidessupportfortheideaofrationallearning,whichwediscuss later. Convergencepropertiescomeinvariousflavors. Herewesurveyfourofthem. Firstofall,theholygrailhasbeenshowingconvergencetostationarystrategies whichform aNashequilibriumofthestagegame. Infactoftenthis isthe hidden motiveoftheresearch. Ithasbeennotedthatgametheoryissomewhatunusualin havingthe notion ofan equilibriumwithoutassociateddynamicsthatgive rise to the equilibrium. Showing that the equilibrium arises naturally would correct this anomaly.4 A second approach recognizes that actual convergence to Nash equilibria is a rare occurrence undermany learning processes. It pursues an alternative: not requiring that the agents converge to a strategy profile that is a Nash equilibrium, butratherrequiringthattheempiricalfrequencyofplayconvergetosuchanequilibrium. For example, consider