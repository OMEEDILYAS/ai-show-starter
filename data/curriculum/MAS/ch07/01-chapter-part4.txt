more than twoplayers. 7.2 Fictitiousplay fictitiousplay Fictitious play is one of the earliest learning rules. It was actually not proposed initiallyasalearningmodelatall,butratherasaniterativemethodforcomputing Nash equilibria in zero-sum games. It happens to not be a particularly effective wayofperformingthis computation,butsinceitemploysanintuitiveupdaterule, itisusuallyviewedasamodeloflearning,albeitasimplisticone,andsubjectedto convergenceanalysesofthesortdiscussedabove. Fictitious play is an instance of model-basedlearning, in which the learner explicitlymaintainsbeliefsabouttheopponent’sstrategy. Thestructureofsuchtechniquesisstraightforward. Initializebeliefsabouttheopponent’sstrategy repeat Playabestresponsetotheassessedstrategyoftheopponent Observetheopponent’sactualplayandupdatebeliefsaccordingly Note that in this scheme the agent is oblivious to the payoffs obtained or obtainable by other agents. We do however assume that the agent knows his own payoffmatrixinthestagegame(i.e.,thepayoffhewouldgetineachactionprofile, whetherornotencounteredinthepast). Infictitious play,anagentbelievesthathisopponentis playingthemixedstrategygivenbytheempiricaldistributionoftheopponent’spreviousactions. Thatis, ifA is the setofthe opponent’sactions, andforeverya Awe let w(a) bethe ∈ numberoftimesthattheopponenthasplayedactiona,thentheagentassessesthe probabilityofaintheopponent’smixedstrategyas w(a) P(a) = . w(a′) a′∈A Forexample,inarepeatedPrisoner’sPDilemmagame,iftheopponenthasplayed C,C,D,C,D in the first five games, before the sixth game he is assumed to be playingthemixedstrategy(0.6,0.4). Notethatwecanrepresentaplayer’sbeliefs witheitheraprobabilitymeasureorwiththesetofcounts(w(a ),...,w(a )). 1 k We have notfully specifiedfictitious play. There existdifferentversionsoffictitiousplaywhichdifferonthetie-breakingmethodusedtoselectanactionwhen there is more than one best response to the particular mixed strategy induced by UncorrectedmanuscriptofMultiagentSystems,publishedbyCambridgeUniversityPress Revision1.1©Shoham&Leyton-Brown,2009,2010. 7.2 Fictitiousplay 207 Heads Tails Heads 1, 1 1,1 − − Tails 1,1 1, 1 − − Figure7.4: MatchingPenniesgame. an agent’s beliefs. In general the tie-breaking rule chosen has little effect on the resultsoffictitiousplay. On the otherhand, fictitious play is verysensitiveto the players’initial beliefs. This choice, which can be interpreted as action counts that were observedbefore thestartofthegame,canhavearadicalimpactonthelearningprocess. Notethat onemustpicksomenonemptypriorbeliefforeachagent;thepriorbeliefscannot be(0,...,0)sincethisdoesnotdefineameaningfulmixedstrategy. Fictitious playis somewhatparadoxicalin thateachagentassumesastationary policyoftheopponent,yetnoagentplaysastationarypolicyexceptwhentheprocess happensto convergeto one. The followingexampleillustrates the operation offictitious play. Recallthe Matching Pennies gamefrom Chapter3, reproduced hereasFigure7.4. TwoplayersareplayingarepeatedgameofMatchingPennies. Eachplayerisusingthefictitiousplaylearningruletoupdatehisbeliefsandselect actions. Player 1 begins the game with the prior belief that player 2 has played heads1.5timesandtails2times. Player2beginswiththepriorbeliefthatplayer1 hasplayedheads2timesandtails1.5times. Howwilltheplayersplay? ThefirstsevenroundsofplayofthegameisshowninTable7.1. Round 1’saction 2’saction 1’sbeliefs 2’sbeliefs 0 (1.5,2) (2,1.5) 1 T T (1.5,3) (2,2.5) 2 T H (2.5,3) (2,3.5) 3 T H (3.5,3) (2,4.5) 4 H H (4.5,3) (3,4.5) 5 H H (5.5,3) (4,4.5) 6 H H (6.5,3) (5,4.5) 7 H T (6.5,4) (6,4.5) . . . . . . . . . . . . . . . Table7.1: FictitiousplayofarepeatedgameofMatchingPennies. Asyoucansee,eachplayerendsupalternatingbackandforthbetweenplaying heads and tails. In fact, as the number of rounds tends to infinity, the empiriFreeforon-screenuse;pleasedonotdistribute.Youcangetanotherfreecopy ofthisPDFororderthebookathttp://www.masfoundations.org. 208 7 LearningandTeaching cal distribution of the play of each player will convergeto (0.5,0.5). If we take thisdistributiontobethemixedstrategyofeachplayer,theplayconvergestothe uniqueNashequilibriumofthenormalformstagegame,thatinwhicheachplayer playsthemixedstrategy(0.5,0.5). Fictitious play has several nice properties. First, connections can be shown to pure-strategyNashequilibria,whentheyexist. steadystate Definition7.2.1(Steadystate) Anactionprofileaisasteadystate(orabsorbing state)offictitiousplayifitisthecasethatwheneveraisplayedatroundtitisalso absorbingstate playedatroundt+1(andhenceinallfutureroundsaswell). The following two theorems establish a tight connectionbetween steady states andpure-strategyNashequilibria. Theorem7.2.2 If a pure-strategy profile is a strict Nash equilibrium of a stage game,thenitisasteadystateoffictitiousplayintherepeatedgame. Note that the pure-strategy profile must be a strict Nash equilibrium, which means that no agent can deviate to another action without strictly decreasing its payoff. Wealsohaveaconverseresult. Theorem7.2.3 If a pure-strategyprofile is a steady state of fictitious play in the repeatedgame,thenitisa(possiblyweak)Nashequilibriuminthestagegame. Ofcourse,onecannotguaranteethatfictitiousplayalwaysconvergestoaNash equilibrium,ifonlybecauseagentscanonlyplaypurestrategiesandapure-strategy Nashequilibrium may notexistin a givengame. However,while the stage game strategiesmaynotconverge,theempiricaldistributionofthestagegamestrategies over multiple iterations may. And indeed this was the case in the Matching Pennies example given earlier, where the empirical distribution of the each player’s strategyconvergedtotheirmixedstrategyinthe(unique)Nashequilibriumofthe game. Thefollowingtheoremshowsthatthiswasnoaccident. Theorem7.2.4 Iftheempiricaldistributionofeachplayer’sstrategiesconverges infictitiousplay,thenitconvergestoaNashequilibrium. This seems like a powerful result. However, notice that although the theorem givessufficient conditionsforthe empiricaldistribution of the players’actions