one approach is to exploit independence properties of the MDP. One case where this arises is whenthestatescanbedescribedbyfeaturevectors;eachfeaturecantakeonmany values,andthusthenumberofstatesisexponentialinthenumberoffeatures. One wouldideallyliketosolvetheMDPintimepolynomialinthenumberoffeatures rather than the number of states, and indeed techniques have been developed to Freeforon-screenuse;pleasedonotdistribute.Youcangetanotherfreecopy ofthisPDFororderthebookathttp://www.masfoundations.org. 24 2 DistributedOptimization 2 1 4 1 3 - 3 - a c a c agent agent a a 2(cid:0)(cid:0) (cid:0)(cid:0) (cid:18) i (cid:0)(cid:0)(cid:0)(cid:0) (cid:0)(cid:0)(cid:18) i6@@@@@ 1 2(cid:0)(cid:0) (cid:0)(cid:0) (cid:18) i (cid:0)(cid:0)(cid:18) i6@@@@@ 1 2(cid:0)(cid:0) (cid:0)(cid:0)(cid:0)(cid:0)(cid:0) @@@@@ @@@@ @R0 4(cid:0)(cid:0) (cid:0) @@@@@ @@@@ @R0 s 2 2(cid:0)(cid:0)(cid:0)(cid:0)(cid:0) 3 t s 2 2 (cid:0) 3 t (cid:0)(cid:0)(cid:0)(cid:0)(cid:0) (cid:0) @@ (cid:0)(cid:18) @@ (cid:0)(cid:18) i (cid:0)(cid:0)(cid:0)(cid:0)(cid:0) (cid:0) i i (cid:0) (cid:0) i 2@@ @@ R ?(cid:0)(cid:0)(cid:0)(cid:0)(cid:0) (cid:0) 5 2@@ @@ R ?(cid:0) (cid:0) 5 agent b b - d agent b b - d 3 3 2 0 3 4 i firsttrial i isecondtrial i 4 1 3 - a c 2(cid:0) (cid:0)(cid:18) i (cid:0)(cid:0)(cid:0)(cid:0) (cid:0)(cid:0)(cid:18) 6i @@@@@ 1 5(cid:0) (cid:0)(cid:0)(cid:0)(cid:0)(cid:0) @@@@@ @@@@ @R0 s 2 2(cid:0)(cid:0)(cid:0)(cid:0)(cid:0) 3 t (cid:0)(cid:0)(cid:0)(cid:0)(cid:0) i@@@@@ (cid:0)(cid:0)(cid:0)(cid:0)(cid:0) (cid:0) (cid:0)(cid:18) i 2@@@@@ @@@@ @R ?(cid:0)(cid:0)(cid:0)(cid:0)(cid:0) (cid:0) 5 - b d 3 3 4 i thirdtrial i Figure2.5: ThreetrialsofLRTA∗(2) tacklesuchMDPswithfactoredstatespaces. We do not address that problem here, but instead on a similar one that has to multiagentMDP do with the modularityof actions rather than ofstates. In a multiagent MDPany (global)actionaisreallyavectoroflocalactions(a ,...,a ),onebyeachofn 1 n agents. Theassumptionhereisthattherewardiscommon,sothereisnoissueof competition among the agents. There is not even a problem of coordination; we have the luxury of a central planner(but see discussion at the end of this section of parallelizability). The only problem is that the numberof globalactions is exponentialinthenumberofagents. CanwesomehowsolvetheMDPotherthanby enumeratingallpossibleactioncombinations? Wewillnotaddressthisproblem,whichisquiteinvolved,infullgenerality. Instead we will focus on an easier subproblem. Suppose that the Q values for the optimal policy have already been computed. How hard is it to decide on which actioneachagentshouldtake? Sinceweareassumingawaytheproblemofcoordinationbypositingacentralplanner,onthefaceofittheproblemisstraightforward. In Appendix C we state that once the optimal (or close to optimal) Q values are computed, the optimal policy is “easily” recovered; the optimal action in state s is argmax Qπ∗(s,a). But ofcourse if a ranges overan exponentialnumberof a choicesbyallagents,“easy”becomes“hard.” Canwedobetterthannaivelyenumeratingoverallactioncombinationsbytheagents? UncorrectedmanuscriptofMultiagentSystems,publishedbyCambridgeUniversityPress Revision1.1©Shoham&Leyton-Brown,2009,2010. 2.2 ActionselectioninmultiagentMDPs 25 In general the answer is no, but in practice, the interaction among the agents’ actionscan be quite limited, which canbe exploitedboth in the representationof theQfunctionandinthemaximizationprocess.Specifically,insomecaseswecan associateanindividualQ functionwitheachagenti, andexpresstheQfunction i (eitherpreciselyorapproximately)asalinearsumoftheindividualQ s: i n Q(s,a) = Q (s,a). i i=1 X Themaximizationproblemnowbecomes n argmax Q (s,a). i a i=1 X This in and of itself is not very useful, as one still needs to look at the set of all globalactions a, which is exponentialin n, the numberofagents. However,it is often also the case that each individualQ dependsonly on a small subset ofthe i variables. Forexample,imagineametal-reprocessingplantwithfourlocations,eachwitha distinctfunction:oneforloadingcontaminatedmaterialandunloadingreprocessed material;oneforcleaningtheincomingmaterial;oneforreprocessingthecleaned material; and one for eliminating the waste. The material flow among them is depictedinFigure2.6. out Station1: Station2: in LoadandUnload Clean Station4: Station3: EliminateWaste Process Figure2.6: Ametal-reprocessingplant Each station canbe in one ofseveralstates, dependingon the load atthattime. Theoperatorofthestationhastwoactionsavailable: “passmaterialtonextstation inprocess,”and“suspendflow.” Thestateoftheplantisafunctionofthestateof each of the stations; the higher the utilization of existing capacity the better, but exceeding full capacity is detrimental. Clearly, in