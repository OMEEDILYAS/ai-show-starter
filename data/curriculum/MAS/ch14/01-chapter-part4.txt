For example, in the Muddy Children problem we used the partition model to represent the knowledge state of the children after each time thefatheraskshisquestion,butdidnotgiveaformalaccountforhowthesystem transitions from onestate to the other. This section is devotedto discussingsuch dynamics. We will first consider the problem of belief revision, which is the process of revisinganexisting state ofbeliefonthe basis ofnewlylearnedinformation. We will consider the revision of both qualitative and quantitative (i.e., probabilistic) beliefs.Thenwewillbrieflylookatdynamicoperationsonbeliefsthataredifferent fromrevision,suchasupdateandfusion. 14.2.1 Beliefrevision Onewayinwhichtheknowledgeandbeliefofanagentchangeiswhentheagent learnsnewfacts,whetherbyobservingtheworldorbybeinginformedbyanother agent. Whetherthebeliefsarecategorical(asinthelogicalsetting)orquantitative beliefrevision (asintheprobabilisticsetting),wecallthisprocessbeliefrevision. When the new information is consistent with the old beliefs, the process is straightforward. In the case of categorical beliefs, one simply adds the new beliefstotheoldonesandtakesthelogicalclosureoftheunion. Thatis, considera knowledgebase(orbeliefbase—hereitdoesnotmatter)K andnewinformation ϕ such that K = ϕ. The result of revising K by ϕ, written K ϕ, is simply 6| ¬ ∗ Cn(K,ϕ),whereCndenotesthelogicalclosureoperator. Orthoughtofsemantically,themodelsofK ϕconsistoftheintersectionofthemodelsofK andthe ∗ modelsofϕ. The situation is equally straightforward in the probabilistic case. Consider a prior belief in the form of a probability distribution P() and new information ϕ · suchthatP(ϕ) > 0. P ϕisthensimplytheposteriordistributionP( ϕ). ∗ · | UncorrectedmanuscriptofMultiagentSystems,publishedbyCambridgeUniversityPress Revision1.1©Shoham&Leyton-Brown,2009,2010. 14.2 Dynamicsofknowledgeandbelief 443 Note that in both the logical and probabilistic settings, the assumption that the newinformationisconsistentwiththepriorbelief(orknowledge)iscritical. Otherwise, in the logicalsettingthe resultofrevisionyieldsthe emptysetofmodels, andin the probabilistic casethe resultis undefined. Thus the bulkofthe work in beliefrevisionliesintryingtocapturehowbeliefsarerevisedbyinformationthat isinconsistentwiththepriorbeliefs(and,giventheirdefeasibility,thesearereally beliefs,asopposedtoknowledge). One might be tempted to argue that this is a waste of time. If an agent is misguided enough to hold false beliefs, let him suffer the consequences. But this is notatenableposition. First,itisnotonlytheagentwhosufferstheconsequences, but also other agents—and we, the modelers—who must reason about him. But beyondthat, there are good reasons why agents might hold firm beliefs and later retract them. In the logical case, if an agent were to wait for foolproof evidence beforeadoptinganybelief,theagentwouldneverbelieveanythingbuttautologies. default Indeed,thenotionofbeliefisintimatelytiedtothatofdefaultreasoningandnonreasoning monotonicreasoning,whicharemotivatedbyjustthisobservation. In the probabilistic case too there are times at which it is unnatural to assign nonmonotonic an event a probability other than zero. We encounter this, in particular, in the reasoning contextofnoncooperativegametheory. Therearesituationsinwhichitisastrictly dominantstrategy(seeSection3.4.3)foranagenttotakeacertainaction,asinthe followingexample. Two foes, Lance and Lot, about to enter into a duel. Each of them mustchooseaweaponandthendecideonafightingtactic. Lancecan choose among two swords—an old, blunt sword, and a new, sharp one. The new one is much better than the old, regardless of the weapon selected by Lot and the tactics selected by either foe. So inselectinghisfightingtactic,LotisjustifiedinassumingthatLance will have selected the new sword with probability one. But what shouldLotdoifheseesthatLanceselectedtheoldswordafterall? Ifthisexampleseemsabitunnatural,thereadermightrefertothediscussionof backward backwardinductioninChapter3. induction Indeed,agreatdealofattentionhasbeenpaidtobeliefrevisionbyinformation inconsistentwiththeinitialbeliefs. Wefirstdescribetheaccountofbeliefrevision inthelogicalsetting;wethenshowhowtheaccountintheprobabilisticsettingis essentiallythesame. Logicalbeliefrevision: TheAGMmodel Westartourdiscussionofbeliefrevisionsemanticallyandwithafamiliarstructure— the KB-models of Section 13.7. In that section, KB-models were used to distinguishknowledgefrom(acertainkindof)belief.Hereweusethemforanadditional purpose,namely,toreasonaboutconditionalbeliefs. Technically,inSection13.7, KB-models were used to give meaning to the two modal operators K and B . i i Freeforon-screenuse;pleasedonotdistribute.Youcangetanotherfreecopy ofthisPDFororderthebookathttp://www.masfoundations.org. 444 14 BeyondBelief:Probability,DynamicsandIntention Givenaparticularworld,K wasdefinedastruthinallworlds“downward”fromit i andB was defined(looselyspeaking)astruth inallworldsinthe“bottom-most” i cluster. But the KB-model can be mined for further information, and here is the intuition. Imagine a KB-model, and a piece of evidenceϕ. Now erase from that modelalltheworldsthatdonotsatisfyϕandallthelinkstoandfromthoseworlds; theresultis a new, reducedKB-model. Thenewbeliefs ofthe agent,aftertaking ϕintoaccount,arethebeliefsinthisreducedKB-model. Thefollowingdefinition makesthisprecise. Definition14.2.1(BeliefrevisioninaKB-model) GivenaKB-modelA= (W,π, 1 ≤ ,..., ) over Σ and any ϕ Σ, let W(ϕ) = w W A,w =