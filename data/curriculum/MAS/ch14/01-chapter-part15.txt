to Peirce [1965]. A recentreview of modal logic for games and information change appears in van der Hoek and Pauly [2006]. Our discussion of coalition logiciscoveredthereindetail,andoriginallyappearedinPauly[2002]. In general, belief dynamics still constitute an active area of research, and the interestedreaderwillundoubtedlywanttostudytherecentliterature,primarilyin artificialintelligenceandphilosophicallogic. The literature on formal theories of “motivational” attitudes, such as desires, goals, and intentions, is much sparser than the literature on the “informational" attitudes discussed earlier. There are fewer publications on these topics, and the results are still preliminary (whichis reflected in the style andlength ofthe book section). The materialpresentedis basedlargelyonworkin artificialintelligence byCohenandLevesque[1990;1991],whichinturnwasinspiredbyphilosophical work such as that of Bratman [1987]. The Cohen-Levesque formulation has attractedcriticismandalternativeformulations,someofwhichcanbefoundinRao andGeorgeff[1991],RaoandGeorgeff[1998],Singh[1992],Meyeretal. [1999], and van der Hoek and Wooldridge [2003]. Much of this literature is surveyedin Wooldridge[2000]. Thisareapresentsmanyopportunitiesforfurtherresearch. UncorrectedmanuscriptofMultiagentSystems,publishedbyCambridgeUniversityPress Revision1.1©Shoham&Leyton-Brown,2009,2010. Appendices: Technical Background A Probability Theory Probability theory provides a formal framework for the discussion of chance or uncertainty.Thisappendixreviewssomekeyconceptsofthetheoryandestablishes notation.However,itglossesoversomedetails(e.g.,pertainingtomeasuretheory). Therefore,theinterestedreaderisencouragedtoconsultatextbookonthetopicfor amorecomprehensivepicture. A.1 Probabilisticmodels Aprobabilisticmodelisdefinedasatuple(Ω, ,P),where: F samplespace • Ωisthesamplespace,alsocalledtheeventspace; eventspace • is aσ-algebraoverΩ; thatis, 2Ω andis closedunderintersectionand F F ⊆ countableunion;and probability • P : [0,1]istheprobabilitydensityfunction(PDF). F 7→ densityfunction Intuitively, the sample space is a set of things that can happen in the world accordingto ourmodel. Forexample,in a modelofa six-sideddie, we mighthave Ω = 1,2,3,4,5,6 . Theσ-field isacollectionofmeasurableevents. isre- { } F F quiredbecausesomeoutcomesinΩmaynotbemeasurable;thus,wemustdefine ourprobabilitydensityfunctionP over ratherthanoverΩ. However,in many F cases, such as the six-sided die example, all outcomes are measurable. In those caseswecan equate with 2Ω andviewthe probabilityspaceas thepair (Ω,P) F andP asP :2Ω [0,1]. Weassumethisinthefollowing. 7→ A.2 Axiomsofprobability theory TheprobabilitydensityfunctionP mustsatisfythefollowingaxioms. 1. ForanyA Ω,P( ) = 0 P(A) P(Ω) = 1. ⊆ ∅ ≤ ≤ 2. ForanypairofdisjointsetsA,A′ Ω,P (A A′) = P(A)+P(A′). ⊂ ∪ 468 A ProbabilityTheory Thatis,allprobabilitiesmustbeboundedby0and1;0istheprobabilityofthe emptysetand1the probabilityofthe wholesamplespace. Second, whensetsof outcomesfromthesamplespacearenonoverlapping,theprobabilityofachieving an outcome from either of the sets is the sum of the probabilities of achieving an outcome from each of the sets. We can infer from these rules that if two sets A,A′ Ωarenotdisjoint,P (A A′) = P(A)+P(A′) P (A A′). ⊆ ∪ − ∩ A.3 Marginalprobabilities We are often concerned with sample spaces Ω that are defined as the Cartesian productofasetofrandomvariablesX ,...,X withdomains ,..., respec1 n 1 n tively. Thus,inthissetting,Ω = n . Ourdensityfunctio X nP isth X usdefined i=1X i overfull assignmentsofvaluesto ourvariables,suchas P(X = x ,...,X = 1 1 n Q marginal x ). However,sometimeswewanttoaskaboutmarginalprobabilities: theproban probability bilitythatasinglevariableX takessomevaluex . Wedefine i i i ∈ X P(X = x )= P(X = x ,...,X = x ). i i 1 1 n n ··· ··· x X1∈X1 xi−X1∈Xi−1xi+X1∈Xi+1 xnX ∈Xn Fromthisdefinitionandfromtheaxiomsgivenearlierwecanalsoinferthat,for example, P(X = x )= P(X = x andX = x ). i i i i j j x Xj∈Xj A.4 Conditionalprobabilities We say that two random variables X and X are independent when P(X = i j i x andX = x ) = P(X = x ) P(X = x )forallvaluesx ,x . i j j i i j j i i j j · ∈ X ∈ X Often, random variables are not independent. When this is the case, it can