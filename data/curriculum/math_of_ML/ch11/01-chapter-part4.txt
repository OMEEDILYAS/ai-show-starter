  0.001 0.999 0.0   RN×K. (11.19)   ∈  0.0 0.066 0.934    0.0 0.0 1.0  0.0 0.0 1.0 Here the nth row tells us the responsibilities of all mixture components for x . The sum of all K responsibilities for a data point (sum of every n row) is 1. The kth column gives us an overview of the responsibility of thekthmixturecomponent.Wecanseethatthethirdmixturecomponent (third column) is not responsible for any of the first four data points, but takes much responsibility of the remaining data points. The sum of all entries of a column gives us the values N , i.e., the total responsibility of k the kth mixture component. In our example, we get N = 2.058, N = 1 2 2.008, N = 2.934. 3 In the following, we determine the updates of the model parameters µ ,Σ ,π for given responsibilities. We will see that the update equak k k tions all depend on the responsibilities, which makes a closed-form solutiontothemaximumlikelihoodestimationproblemimpossible.However, for given responsibilities we will be updating one model parameter at a time, while keeping the others fixed. After this, we will recompute the responsibilities.Iteratingthesetwostepswilleventuallyconvergetoalocal optimum and is a specific instantiation of the EM algorithm. We will discussthisinsomemoredetailinSection11.3. 11.2.2 Updating the Means Theorem 11.1 (Update of the GMM Means). The update of the mean parametersµ ,k = 1,...,K,oftheGMMisgivenby k (cid:80)N r x µnew = n=1 nk n , (11.20) k (cid:80)N r n=1 nk wheretheresponsibilitiesr aredefinedin(11.17). nk (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 354 DensityEstimationwithGaussianMixtureModels Remark. The update of the means µ of the individual mixture compok nentsin(11.20)dependsonallmeans,covariancematricesΣ ,andmixk ture weights π via r given in (11.17). Therefore, we cannot obtain a k nk closed-formsolutionforallµ atonce. k ♦ Proof From (11.15), we see that the gradient of the log-likelihood with respecttothemeanparametersµ ,k = 1,...,K,requiresustocompute k thepartialderivative ∂p(x n | θ) = (cid:88) K π ∂ N (cid:0) x n | µ j , Σ j (cid:1) = π ∂ N (cid:0) x n | µ k , Σ k (cid:1) (11.21a) ∂µ j ∂µ k ∂µ k j=1 k k = π (x µ )(cid:62)Σ−1 (cid:0) x µ , Σ (cid:1) , (11.21b) k n − k k N n | k k whereweexploitedthatonlythekthmixturecomponentdependsonµ . k Weuseourresultfrom(11.21b)in(11.15)andputeverythingtogether sothatthedesiredpartialderivativeof withrespecttoµ isgivenas L k ∂ (cid:88) N ∂logp(x n θ) (cid:88) N 1 ∂p(x n θ) L = | = | (11.22a) ∂µ ∂µ p(x θ) ∂µ k n=1 k n=1 n | k = (cid:88) N (x µ )(cid:62)Σ−1 π k N (cid:0) x n | µ k , Σ k (cid:1) (11.22b) n − k k (cid:80)K π (cid:0) x µ , Σ (cid:1) n=1 j=1 j N n | j j (cid:124) (cid:123)(cid:122) (cid:125) =rnk N (cid:88) = r (x µ )(cid:62)Σ−1. (11.22c) nk n − k k n=1 Hereweusedtheidentityfrom(11.16)andtheresultofthepartialderivativein(11.21b)togetto(11.22b).Thevaluesr aretheresponsibilities nk wedefinedin(11.17). Wenowsolve(11.22c)forµnew sothat ∂L(µn k ew) = 0(cid:62) andobtain k ∂µ k (cid:88) N r x = (cid:88) N r µnew µnew = (cid:80)N n=1 r nk x n = 1 (cid:88)