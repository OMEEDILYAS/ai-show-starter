(cid:20) (cid:21) 2 1 LetuscomputetheeigendecompositionofA = . 1 2 Step 1: Compute eigenvalues and eigenvectors. The characteristic (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 118 MatrixDecompositions polynomialofAis (cid:18)(cid:20) (cid:21)(cid:19) 2 λ 1 det(A λI) = det − (4.56a) − 1 2 λ − = (2 λ)2 1 = λ2 4λ+3 = (λ 3)(λ 1). (4.56b) − − − − − Therefore, the eigenvalues of A are λ = 1 and λ = 3 (the roots of the 1 2 characteristic polynomial), and the associated (normalized) eigenvectors areobtainedvia (cid:20) (cid:21) (cid:20) (cid:21) 2 1 2 1 p = 1p , p = 3p . (4.57) 1 2 1 1 1 2 2 2 Thisyields (cid:20) (cid:21) (cid:20) (cid:21) 1 1 1 1 p = , p = . (4.58) 1 √2 1 2 √2 1 − Step 2: Check for existence. The eigenvectors p ,p form a basis of 1 2 R2.Therefore,Acanbediagonalized. Step 3: Construct the matrix P to diagonalize A. We collect the eigenvectorsofAinP sothat (cid:20) (cid:21) 1 1 1 P = [p , p ] = . (4.59) 1 2 √2 1 1 − Wethenobtain (cid:20) (cid:21) 1 0 P−1AP = = D. (4.60) 0 3 Equivalently,weget(exploitingthatP−1 = P(cid:62) sincetheeigenvectorsp 1 andp inthisexampleformanONB) 2 (cid:20) (cid:21) (cid:20) (cid:21)(cid:20) (cid:21) (cid:20) (cid:21) 2 1 1 1 1 1 0 1 1 1 = − . (4.61) 1 2 √2 1 1 0 3 √2 1 1 − (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)(cid:124) (cid:123)(cid:122) (cid:125)(cid:124) (cid:123)(cid:122) (cid:125) A P D P(cid:62) Diagonal matrices D can efficiently be raised to a power. Therefore, we can find a matrix power for a matrix A Rn×n via the eigenvalue ∈ decomposition(ifitexists)sothat Ak = (PDP−1)k = PDkP−1. (4.62) ComputingDk isefficientbecauseweapplythisoperationindividually toanydiagonalelement. AssumethattheeigendecompositionA = PDP−1 exists.Then, det(A) = det(PDP−1) = det(P)det(D)det(P−1) (4.63a) Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 4.5 SingularValueDecomposition 119 (cid:89) = det(D) = d (4.63b) ii i allowsforanefficientcomputationofthedeterminantofA. The eigenvalue decomposition requires square matrices. It would be useful to perform a decomposition on general matrices. In the next section, we introduce a more general matrix decomposition technique, the singularvaluedecomposition. 4.5 Singular Value Decomposition The singular value decomposition (SVD) of a matrix is a central matrix decomposition method in linear algebra. It has been referred to as the “fundamentaltheoremoflinearalgebra”(Strang,1993)becauseitcanbe applied to all matrices, not only to square matrices, and it always exists. Moreover, as we will explore in the following, the SVD of a matrix A, which represents a linear mapping Φ : V W, quantifies the change → between the underlying geometry of these two vector spaces. We recommend the work by Kalman (1996) and Roy and Banerjee (2014) for a deeperoverviewofthemathematicsoftheSVD. SVDtheorem Theorem4.22(SVDTheorem). LetAm×n bearectangularmatrixofrank r [0,min(m,n)].TheSVDofAisadecompositionoftheform SVD ∈ singularvalue decomposition A = U Σ V (cid:62) m n m m m n n n (4.64) withanorthogonalmatrixU Rm×mwithcolumnvectorsu ,i = 1,...,m, i andanorthogonalmatrixV ∈Rn×n withcolumnvectorsv ,j = 1,...,n. j Moreover,Σisanm nmat ∈ rixwithΣ = σ (cid:62) 0andΣ = 0, i = j. ii i ij × (cid:54) Thediagonalentriesσ i ,i = 1,...,r,ofΣarecalledthesingularvalues, singularvalues u i are called the left-singular vectors, and v j