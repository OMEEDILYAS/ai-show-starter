z ). (10.31b) −N n i − in i i −N n i − in Thecoordinatesof since b(cid:62) i b i = 1. Setting this partial derivative to 0 yields immediately the theoptimal optimalcoordinates projectionofxn withrespecttothe z = x(cid:62)b = b(cid:62)x (10.32) in n i i n basisvectors b1,...,bM arethe for i = 1,...,M and n = 1,...,N. This means that the optimal cocoordinatesofthe ordinates z of the projection x˜ are the coordinates of the orthogonal in n orthogonal projection (see Section 3.8) of the original data point x onto the oneprojectionofxn n ontotheprincipal dimensionalsubspacethatisspannedbyb i .Consequently: subspace. Theoptimallinearprojectionx˜ ofx isanorthogonalprojection. n n The coordinates of x˜ with respect to the basis (b ,...,b ) are the n 1 M coordinates of the orthogonal projection of x onto the principal subn space. An orthogonal projection is the best linear mapping given the objective(10.29). Thecoordinatesζ ofxin(10.26)andthecoordinatesz ofx˜ in(10.27) m m Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 10.3 ProjectionPerspective 329 must be identical for m = 1,...,M since U⊥ = span[b ,...,b ] is M+1 D theorthogonalcomplement(seeSection3.6)ofU = span[b ,...,b ]. 1 M Remark (Orthogonal Projections with Orthonormal Basis Vectors). Let us brieflyrecaporthogonalprojectionsfromSection3.8.If(b ,...,b )isan 1 D orthonormalbasisofRD then b(cid:62)xisthe j coordinateofthe x˜ = b j (b(cid:62) j b j )−1b(cid:62) j x = b j b(cid:62) j x ∈ RD (10.33) orthogonal projectionofxonto istheorthogonalprojectionofxontothesubspacespannedbythejthba- thesubspace sisvector,andz j = b(cid:62) j xisthecoordinateofthisprojectionwithrespectto spannedbybj. thebasisvectorb thatspansthatsubspacesincez b = x˜.Figure10.8(b) j j j illustratesthissetting. More generally, if we aim to project onto an M-dimensional subspace ofRD,weobtaintheorthogonalprojectionofxontotheM-dimensional subspacewithorthonormalbasisvectorsb ,...,b as 1 M x˜ = B(B(cid:62)B)−1B(cid:62)x = BB(cid:62)x, (10.34) (cid:124) (cid:123)(cid:122) (cid:125) =I where we defined B := [b ,...,b ] RD×M. The coordinates of this 1 M projection with respect to the ordered ∈ basis (b ,...,b ) are z := B(cid:62)x 1 M asdiscussedinSection3.8. We can think of the coordinates as a representation of the projected vector in a new coordinate system defined by (b ,...,b ). Note that al1 M though x˜ RD, we only need M coordinates z ,...,z to represent 1 M ∈ thisvector;theotherD M coordinateswithrespecttothebasisvectors − (b ,...,b )arealways0. M+1 D ♦ So far we have shown that for a given ONB we can find the optimal coordinatesofx˜ byanorthogonalprojectionontotheprincipalsubspace. Inthefollowing,wewilldeterminewhatthebestbasisis. 10.3.3 Finding the Basis of the Principal Subspace To determine the basis vectors b ,...,b of the principal subspace, we 1 M rephrase the loss function (10.29) using the results we have so far. This will make it easier to find the basis vectors. To reformulate the loss function,weexploitourresultsfrombeforeandobtain M M x˜ = (cid:88) z b (10 = .32) (cid:88) (x(cid:62)b )b . (10.35) n mn m n m m m=1 m=1 Wenowexploitthesymmetryofthedotproduct,whichyields (cid:32) (cid:33) M (cid:88) x˜ = b b(cid:62) x . (10.36) n m m n m=1 (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 330 DimensionalityReductionwithPrincipalComponentAnalysis Figure10.9 Orthogonal 6 projectionand displacement 4 vectors.When 2 projectingdata pointsxn(blue) 0 ontosubspaceU1, weobtainx˜n 2 (orange).The − displacementvector 4 x˜n−xnlies − completelyinthe 6 orthogonal − 5 0 5 complementU2of − x 1 U1. x 2 U⊥ U Sincewecangenerallywritetheoriginaldatapointx asalinearcombin nationofallbasisvectors,itholdsthat (cid:32) (cid:33) D D