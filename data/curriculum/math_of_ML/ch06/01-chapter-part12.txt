variable, the variance describes the relation between individual dimensionsoftherandomvariable. variance Definition 6.7 (Variance). The variance of a random variable X with statesx RD andameanvectorµ RD isdefinedas ∈ ∈ V [x] = Cov [x,x] (6.38a) X X = E [(x µ)(x µ)(cid:62)] = E [xx(cid:62)] E [x]E [x](cid:62) (6.38b) X X X X − − −   Cov[x ,x ] Cov[x ,x ] ... Cov[x ,x ] 1 1 1 2 1 D Cov[x 2 ,x 1 ] Cov[x 2 ,x 2 ] ... Cov[x 2 ,x D ] =    . . . . . . ... . . .    . (6.38c) Cov[x ,x ] ... ... Cov[x ,x ] D 1 D D covariancematrix TheD D matrixin(6.38c)iscalledthecovariancematrixofthemul- × tivariaterandomvariableX.Thecovariancematrixissymmetricandpositivesemidefiniteandtellsussomethingaboutthespreadofthedata.On marginal itsdiagonal,thecovariancematrixcontainsthevariancesofthemarginals Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 6.4 SummaryStatisticsandIndependence 191 Figure6.5 6 Two-dimensional datasetswith 4 identicalmeansand variancesalong 2 eachaxis(colored 0 lines)butwith different − 2 covariances. 5 0 5 − x y 6 4 2 0 2 − 5 0 5 − x (a)xandyarenegativelycorrelated. y (b)xandyarepositivelycorrelated. (cid:90) p(x ) = p(x ,...,x )dx , (6.39) i 1 D \i where “ i” denotes “all variables but i”. The off-diagonal entries are the \ cross-covariancetermsCov[x i ,x j ]fori,j = 1,...,D, i = j. cross-covariance (cid:54) Remark. In this book, we generally assume that covariance matrices are positive definite to enable better intuition. We therefore do not discuss cornercasesthatresultinpositivesemidefinite(low-rank)covariancematrices. ♦ When we want to compare the covariances between different pairs of random variables, it turns out that the variance of each random variable affects the value of the covariance. The normalized version of covariance iscalledthecorrelation. Definition 6.8 (Correlation). The correlation between two random vari- correlation ablesX,Y isgivenby Cov[x,y] corr[x,y] = [ 1,1]. (6.40) (cid:112)V[x]V[y] ∈ − Thecorrelationmatrixisthecovariancematrixofstandardizedrandom variables, x/σ(x). In other words, each random variable is divided by its standard deviation (the square root of the variance) in the correlation matrix. The covariance (and correlation) indicate how two random variables arerelated;seeFigure6.5.Positivecorrelationcorr[x,y]meansthatwhen xgrows,theny isalsoexpectedtogrow.Negativecorrelationmeansthat asxincreases,theny decreases. 6.4.2 Empirical Means and Covariances The definitions in Section 6.4.1 are often also called the population mean populationmean and covariance, as itrefers to the truestatistics for the population.In ma- andcovariance chinelearning,weneedtolearnfromempiricalobservationsofdata.Consider a random variable X. There are two conceptual steps to go from (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 192 ProbabilityandDistributions populationstatisticstotherealizationofempiricalstatistics.First,weuse thefactthatwehaveafinitedataset(ofsizeN)toconstructanempirical statisticthatisafunctionofafinitenumberofidenticalrandomvariables, X ,...,X . Second, we observe the data, that is, we look at the realiza1 N tion x ,...,x of each of the random variables and apply the empirical 1 N statistic. Specifically,forthemean(Definition6.4),givenaparticulardatasetwe empiricalmean canobtainanestimateofthemean,whichiscalledtheempiricalmeanor samplemean samplemean.Thesameholdsfortheempiricalcovariance. empiricalmean Definition6.9(EmpiricalMeanandCovariance). Theempiricalmeanvector is the arithmetic average of the observations for each variable, and it isdefinedas N 1 (cid:88) x¯ := x , (6.41) N n n=1 wherex RD. n ∈ empiricalcovariance Similartotheempiricalmean,theempiricalcovariancematrixisaD D × matrix N 1 (cid:88) Σ := (x x¯)(x x¯)(cid:62). (6.42) N n − n − n=1 Throughoutthe To compute the statistics for a particular dataset, we would use the book,weusethe empirical realizations (observations) x ,...,x and use (6.41) and (6.42). Em1 N covariance,whichis pirical covariance matrices are symmetric, positive semidefinite (see Secabiasedestimate. tion3.2.3). Theunbiased