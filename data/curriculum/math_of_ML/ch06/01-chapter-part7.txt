are in fact two distinct concepts when talking about distributions. First is the idea of a pdf (denoted by f(x)), which is a nonnegative function that sums to one. Second is the law of a random variable X, that is, the association of a random variable X with thepdff(x). ♦ (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 182 ProbabilityandDistributions Figure6.3 2.0 Examplesof (a)discreteand 1.5 (b)continuous uniform 1.0 distributions.See 0.5 Example6.3for detailsofthe 0.0 distributions. 1 0 1 2 − z )z= Z(P 2.0 1.5 1.0 0.5 0.0 1 0 1 2 − x (a)Discretedistribution )x(p (b)Continuousdistribution For most of this book, we will not use the notation f(x) and F (x) as X we mostly do not need to distinguish between the pdf and cdf. However, wewillneedtobecarefulaboutpdfsandcdfsinSection6.7. 6.2.3 Contrasting Discrete and Continuous Distributions RecallfromSection6.1.2thatprobabilitiesarepositiveandthetotalprobability sums up to one. For discrete random variables (see (6.12)), this implies that the probability of each state must lie in the interval [0,1]. However,forcontinuousrandomvariablesthenormalization(see(6.15)) does not imply that the value of the density is less than or equal to 1 for uniformdistribution all values. We illustrate this in Figure 6.3 using the uniform distribution forbothdiscreteandcontinuousrandomvariables. Example 6.3 Weconsidertwoexamplesoftheuniformdistribution,whereeachstateis equally likely to occur. This example illustrates some differences between discreteandcontinuousprobabilitydistributions. Let Z be a discrete uniform random variable with three states z = { Theactualvaluesof 1.1,z = 0.3,z = 1.5 . Theprobabilitymassfunctioncanberepresented − } thesestatesarenot asatableofprobabilityvalues: meaningfulhere, andwedeliberately z 1.1 0.3 1.5 − chosenumbersto drivehomethe P(Z =z) 1 1 1 3 3 3 pointthatwedonot wanttouse(and Alternatively, we can think of this as a graph (Figure 6.3(a)), where we shouldignore)the orderingofthe use the fact that the states can be located on the x-axis, and the y-axis states. representstheprobabilityofaparticularstate.They-axisinFigure6.3(a) isdeliberatelyextendedsothatisitthesameasinFigure6.3(b). LetX beacontinuousrandomvariabletakingvaluesintherange0.9 (cid:54) X (cid:54) 1.6, as represented by Figure 6.3(b). Observe that the height of the Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 6.3 SumRule,ProductRule,andBayes’Theorem 183 Type “Pointprobability” “Intervalprobability” Table6.1 Nomenclaturefor Discrete P(X =x) Notapplicable probability Probabilitymassfunction distributions. Continuous p(x) P(X (cid:54)x) Probabilitydensityfunction Cumulativedistributionfunction densitycanbegreaterthan1.However,itneedstoholdthat (cid:90) 1.6 p(x)dx = 1. (6.19) 0.9 Remark. There is an additional subtlety with regards to discrete probability distributions. The states z ,...,z do not in principle have any 1 d structure, i.e., there is usually no way to compare them, for example z = red,z = green,z = blue. However, in many machine learning 1 2 3 applications discrete states take numerical values, e.g., z = 1.1,z = 1 2 − 0.3,z = 1.5, where we could say z < z < z . Discrete states that as3 1 2 3 sume numerical values are particularly useful because we often consider expectedvalues(Section6.4.1)ofrandomvariables. ♦ Unfortunately, machine learning literature uses notation and nomenclature that hides the distinction between the sample space Ω, the target space , and the random variable X. For a value x of the set of possible T outcomes of the random variable X, i.e., x , p(x) denotes the prob- Wethinkofthe ∈ T ability that random variable X has the outcome x. For discrete random outcomexasthe variables, this is written as P(X = x), which is known as the probabil- argumentthat resultsinthe