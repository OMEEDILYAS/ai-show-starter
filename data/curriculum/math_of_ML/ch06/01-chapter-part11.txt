obvious way to “sort” in more than one dimenmode sion (Hallin et al., 2010; Kong and Mizera, 2012). The mode is the most frequently occurring value. For a discrete random variable, the mode is defined as the value of x having the highest frequency of occurrence. For acontinuousrandomvariable,themodeisdefinedasapeakinthedensity p(x). A particular density p(x) may have more than one mode, and furthermoretheremaybeaverylargenumberofmodesinhigh-dimensional distributions. Therefore, finding all the modes of a distribution can be computationallychallenging. Example 6.4 Considerthetwo-dimensionaldistributionillustratedinFigure6.4: (cid:18) (cid:12)(cid:20) (cid:21) (cid:20) (cid:21)(cid:19) (cid:18) (cid:12)(cid:20) (cid:21) (cid:20) (cid:21)(cid:19) (cid:12) 10 1 0 (cid:12) 0 8.4 2.0 p(x) = 0.4 x (cid:12) , +0.6 x (cid:12) , . N (cid:12) 2 0 1 N (cid:12) 0 2.0 1.7 (6.33) (cid:0) (cid:1) We will define the Gaussian distribution µ, σ2 in Section 6.5. Also N shown is its corresponding marginal distribution in each dimension. Observe that the distribution is bimodal (has two modes), but one of the Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 6.4 SummaryStatisticsandIndependence 189 marginal distributions is unimodal (has one mode). The horizontal bimodal univariate distribution illustrates that the mean and median can be different from each other. While it is tempting to define the twodimensional median to be the concatenation of the medians in each dimension, the fact that we cannot define an ordering of two-dimensional points makes it difficult. When we say “cannot define an ordering”, we mean that there is more than one way to define the relation < so that (cid:20) (cid:21) (cid:20) (cid:21) 3 2 < . 0 3 Figure6.4 Mean Illustrationofthe Modes mean,mode,and Median medianfora two-dimensional dataset,aswellas itsmarginal densities. Remark. The expected value (Definition 6.3) is a linear operator. For example,givenareal-valuedfunctionf(x) = ag(x)+bh(x)wherea,b R andx RD,weobtain ∈ ∈ (cid:90) E [f(x)] = f(x)p(x)dx (6.34a) X (cid:90) = [ag(x)+bh(x)]p(x)dx (6.34b) (cid:90) (cid:90) = a g(x)p(x)dx+b h(x)p(x)dx (6.34c) = aE [g(x)]+bE [h(x)]. (6.34d) X X ♦ Fortworandomvariables,wemaywishtocharacterizetheircorrespon- (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 190 ProbabilityandDistributions dence to each other. The covariance intuitively represents the notion of howdependentrandomvariablesaretooneanother. covariance Definition 6.5 (Covariance (Univariate)). The covariance between two univariate random variables X,Y R is given by the expected product ∈ oftheirdeviationsfromtheirrespectivemeans,i.e., Cov [x,y] := E (cid:2) (x E [x])(y E [y]) (cid:3) . (6.35) X,Y X,Y X Y − − Terminology:The Remark. When the random variable associated with the expectation or covarianceof multivariaterandom covarianceisclearbyitsarguments,thesubscriptisoftensuppressed(for variablesCov[x,y] example,E [x]isoftenwrittenasE[x]). X issometimes ♦ referredtoas By using the linearity of expectations, the expression in Definition 6.5 cross-covariance, can be rewritten as the expected value of the product minus the product withcovariance oftheexpectedvalues,i.e., referringto Cov[x,x]. Cov[x,y] = E[xy] E[x]E[y]. (6.36) − variance ThecovarianceofavariablewithitselfCov[x,x]iscalledthevarianceand standarddeviation isdenotedbyV X [x].Thesquarerootofthevarianceiscalledthestandard deviation and is often denoted by σ(x). The notion of covariance can be generalizedtomultivariaterandomvariables. Definition6.6(Covariance(Multivariate)). Ifweconsidertwomultivariate random variables X and Y with states x RD and y RE respec- ∈ ∈ covariance tively,thecovariancebetweenX andY isdefinedas Cov[x,y] = E[xy(cid:62)] E[x]E[y](cid:62) = Cov[y,x](cid:62) RD×E. (6.37) − ∈ Definition 6.6 can be applied with the same multivariate random variable in both arguments, which results in a useful concept that intuitively captures the “spread” of a random variable. For a multivariate random