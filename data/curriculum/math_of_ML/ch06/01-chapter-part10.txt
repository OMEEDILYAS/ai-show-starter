statistics of a distribution provide one useful view of how a random variable behaves, and as the name suggests, provide numbers that summarize and characterize the distribution. We describe the mean and the variance, two wellknown summary statistics. Then we discuss two ways to compare a pair ofrandomvariables:first,howtosaythattworandomvariablesareindependent;andsecond,howtocomputeaninnerproductbetweenthem. Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 6.4 SummaryStatisticsandIndependence 187 6.4.1 Means and Covariances Meanand(co)varianceareoftenusefultodescribepropertiesofprobability distributions (expected values and spread). We will see in Section 6.6 that there is a useful family of distributions (called the exponential family),wherethestatisticsoftherandomvariablecaptureallpossibleinformation. The concept of the expected value is central to machine learning, and the foundational concepts of probability itself can be derived from the expectedvalue(Whittle,2000). Definition6.3(ExpectedValue). Theexpectedvalueofafunctiong : R expectedvalue RofaunivariatecontinuousrandomvariableX p(x)isgivenby → ∼ (cid:90) E [g(x)] = g(x)p(x)dx. (6.28) X X Correspondingly, the expected value of a function g of a discrete random variableX p(x)isgivenby ∼ (cid:88) E [g(x)] = g(x)p(x), (6.29) X x∈X where is the set of possible outcomes (the target space) of the random X variableX. Inthissection,weconsiderdiscreterandomvariablestohavenumerical outcomes. This can be seen by observing that the function g takes real numbersasinputs. Theexpectedvalue ofafunctionofa Remark. We consider multivariate random variables X as a finite vector randomvariableis of univariate random variables [X 1 ,...,X D ](cid:62). For multivariate random sometimesreferred variables,wedefinetheexpectedvalueelementwise toasthelawofthe unconscious E [g(x )]  statistician(Casella E X [g(x)] =   X1 . . . 1   ∈ RD, (6.30) a S n ec d ti B o e n rg 2 e .2 r, ). 2002, E [g(x )] XD D where the subscript E indicates that we are taking the expected value Xd withrespecttothedthelementofthevectorx. ♦ Definition 6.3 defines the meaning of the notation E as the operator X indicating that we should take the integral with respect to the probability density (for continuous distributions) or the sum over all states (for discrete distributions). The definition of the mean (Definition 6.4), is a specialcaseoftheexpectedvalue,obtainedbychoosingg tobetheidentityfunction. Definition 6.4 (Mean). The mean of a random variable X with states mean (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 188 ProbabilityandDistributions x RD isanaverageandisdefinedas ∈ E [x ]  X1 1 E X [x] =   . . .   ∈ RD, (6.31) E [x ] XD D where  (cid:90)    x d p(x d )dx d ifX isacontinuousrandomvariable E xd [x d ] := (cid:88)X x p(x = x ) ifX isadiscreterandomvariable   i d i  xi∈X (6.32) for d = 1,...,D, where the subscript d indicates the corresponding dimension of x. The integral and sum are over the states of the target X spaceoftherandomvariableX. In one dimension, there are two other intuitive notions of “average”, median which are the median and the mode. The median is the “middle” value if wesortthevalues,i.e.,50%ofthevaluesaregreaterthanthemedianand 50%aresmallerthanthemedian.Thisideacanbegeneralizedtocontinuousvaluesbyconsideringthevaluewherethecdf(Definition6.2)is0.5. For distributions, which are asymmetric or have long tails, the median provides an estimate of a typical value that is closer to human intuition than the mean value. Furthermore, the median is more robust to outliers than the mean. The generalization of the median to higher dimensions is non-trivial as there is no