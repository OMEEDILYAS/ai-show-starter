Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 9.1 ProblemFormulation 291 9.1 Problem Formulation Because of the presence of observation noise, we will adopt a probabilistic approach and explicitly model the noise using a likelihood function. More specifically, throughout this chapter, we consider a regression problemwiththelikelihoodfunction p(y x) = (cid:0) y f(x), σ2(cid:1) . (9.1) | N | Here, x RD are inputs and y R are noisy function values (targets). ∈ ∈ With(9.1),thefunctionalrelationshipbetweenxandy isgivenas y = f(x)+(cid:15), (9.2) (cid:0) (cid:1) where (cid:15) 0, σ2 is independent, identically distributed (i.i.d.) Gaus- ∼ N sian measurement noise with mean 0 and variance σ2. Our objective is to find a function that is close (similar) to the unknown function f that generatedthedataandthatgeneralizeswell. In this chapter, we focus on parametric models, i.e., we choose a parametrizedfunctionandfindparametersθthat“workwell”formodelingthe data. For the time being, we assume that the noise variance σ2 is known and focus on learning the model parameters θ. In linear regression, we consider the special case that the parameters θ appear linearly in our model.Anexampleoflinearregressionisgivenby p(y x,θ) = (cid:0) y x(cid:62)θ, σ2(cid:1) (9.3) | N | y = x(cid:62)θ+(cid:15), (cid:15) (cid:0) 0, σ2(cid:1) , (9.4) ⇐⇒ ∼ N where θ RD are the parameters we seek. The class of functions de- ∈ scribed by (9.4) are straight lines that pass through the origin. In (9.4), wechoseaparametrizationf(x) = x(cid:62)θ. ADiracdelta(delta The likelihood in (9.3) is the probability density function of y evalu- function)iszero ated at x(cid:62)θ. Note that the only source of uncertainty originates from the everywhereexcept atasinglepoint, observation noise (as x and θ are assumed known in (9.3)). Without obanditsintegralis1. servation noise, the relationship between x and y would be deterministic Itcanbeconsidered and(9.3)wouldbeaDiracdelta. aGaussianinthe limitofσ2→0. likelihood Example 9.1 For x,θ R the linear regression model in (9.4) describes straight lines ∈ (linear functions), and the parameter θ is the slope of the line. Figure9.2(a)showssomeexamplefunctionsfordifferentvaluesofθ. Linearregression The linear regression model in (9.3)–(9.4) is not only linear in the pa- referstomodelsthat rameters, but also linear in the inputs x. Figure 9.2(a) shows examples arelinearinthe parameters. of such functions. We will see later that y = φ(cid:62)(x)θ for nonlinear transformationsφisalsoalinearregressionmodelbecause“linearregression” (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 292 LinearRegression Figure9.2 Linear 20 regressionexample. (a)Example 0 functionsthatfall intothiscategory; 20 (b)trainingset; − 10 0 10 − x (c)maximum likelihoodestimate. y 10 0 10 − 10 5 0 5 10 − − x (a)Examplefunctions(straight lines)thatcanbedescribedusingthelinearmodelin(9.4). y 10 0 10 − 10 5 0 5 10 − − x (b)Trainingset. y (c) Maximum likelihood estimate. refers to models that are “linear in the parameters”, i.e., models that describe a function by a linear combination of input features. Here, a “feature”isarepresentationφ(x)oftheinputsx. In the following, we will discuss in more detail how to find good parameters θ and how to evaluate whether a parameter set “works well”. Forthetimebeing,weassumethatthenoisevarianceσ2 isknown. 9.2 Parameter Estimation Consider the linear regression setting (9.4) and assume we are given a trainingset training set := (x 1 ,y 1 ),...,(x N ,y N ) consisting of N inputs x n Figure9.3 RD and corr D espond { ing observations/targe } ts y