1(cid:0) σ−2y(cid:62)y 2σ−2y(cid:62)Φθ+θ(cid:62)σ−2Φ(cid:62)Φθ+θ(cid:62)S−1θ − 2 − 0 (9.46a) 2m(cid:62)S−1θ+m(cid:62)S−1m (cid:1) − 0 0 0 0 0 = 1(cid:0) θ(cid:62)(σ−2Φ(cid:62)Φ+S−1)θ 2(σ−2Φ(cid:62)y+S−1m )(cid:62)θ (cid:1) +const, − 2 0 − 0 0 (9.46b) where the constant contains the black terms in (9.46a), which are independent of θ. The orange terms are terms that are linear in θ, and the blue terms are the ones that are quadratic in θ. Inspecting (9.46b), we find that this equation is quadratic in θ. The fact that the unnormalized log-posterior distribution is a (negative) quadratic form implies that the posteriorisGaussian,i.e., p(θ , ) = exp(logp(θ , )) exp(logp( ,θ)+logp(θ)) |X Y |X Y ∝ Y|X (9.47a) exp (cid:16) 1(cid:0) θ(cid:62)(σ−2Φ(cid:62)Φ+S−1)θ 2(σ−2Φ(cid:62)y+S−1m )(cid:62)θ (cid:1) (cid:17) , ∝ − 2 0 − 0 0 (9.47b) whereweused(9.46b)inthelastexpression. Theremainingtaskisittobringthis(unnormalized)Gaussianintothe (cid:0) (cid:1) form that is proportional to θ m , S , i.e., we need to identify the N N N | mean m and the covariance matrix S . To do this, we use the concept N N ofcompletingthesquares.Thedesiredlog-posterioris completingthe squares log (cid:0) θ m , S (cid:1) = 1 (θ m )(cid:62)S−1(θ m )+const (9.48a) N | N N −2 − N N − N = 1(cid:0) θ(cid:62)S−1θ 2m(cid:62)S−1θ+m(cid:62)S−1m (cid:1) . (9.48b) −2 N − N N N N N Here, we factorized the quadratic form (θ − m N )(cid:62)S− N 1(θ − m N ) into a Sin (cid:0) cep(θ|X, (cid:1) Y)= termthatisquadraticinθalone(blue),atermthatislinearinθ(orange), N mN,SN ,it holdsthat and a constant term (black). This allows us now to find S and m by N N matchingthecoloredexpressionsin(9.46b)and(9.48b),whichyields θ MAP =mN. S−1 = Φ(cid:62)σ−2IΦ+S−1 (9.49a) N 0 S = (σ−2Φ(cid:62)Φ+S−1)−1 (9.49b) ⇐⇒ N 0 and m(cid:62)S−1 = (σ−2Φ(cid:62)y+S−1m )(cid:62) (9.50a) N N 0 0 m = S (σ−2Φ(cid:62)y+S−1m ). (9.50b) ⇐⇒ N N 0 0 (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 308 LinearRegression Remark (General Approach to Completing the Squares). If we are given anequation x(cid:62)Ax 2a(cid:62)x+const , (9.51) 1 − where A is symmetric and positive definite, which we wish to bring into theform (x µ)(cid:62)Σ(x µ)+const , (9.52) 2 − − wecandothisbysetting Σ := A, (9.53) µ := Σ−1a (9.54) andconst = const µ(cid:62)Σµ. 2 1 − ♦ We can see that the terms inside the exponential in (9.47b) are of the form(9.51)with A := σ−2Φ(cid:62)Φ+S−1, (9.55) 0 a := σ−2Φ(cid:62)y+S−1m . (9.56) 0 0 Since A,a can be difficult to identify in equations like (9.46a), it is often helpful to bring these equations into the form (9.51) that decouples quadratic term, linear terms, and constants, which simplifies finding the desiredsolution. 9.3.4 Posterior Predictions In (9.37), we computed the predictive distribution of y at a test input ∗ x using the parameter prior p(θ). In principle, predicting with the pa- ∗ rameter posterior p(θ , ) is not fundamentally different given that |X Y in our conjugate model the prior and posterior are both Gaussian (with different parameters). Therefore, by following the same reasoning as in Section9.3.2,weobtainthe(posterior)predictivedistribution (cid:90) p(y , ,x ) = p(y x ,θ)p(θ , )dθ (9.57a) ∗ ∗ ∗ ∗ |X