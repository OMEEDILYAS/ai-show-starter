1. → For a function f : Rn Rm and a vector x = [x ,...,x ](cid:62) Rn, the 1 n → ∈ correspondingvectoroffunctionvaluesisgivenas   f (x) 1 f(x) =   . . .   ∈ Rm. (5.54) f (x) m Writing the vector-valued function in this way allows us to view a vectorvalued function f : Rn Rm as a vector of functions [f ,...,f ](cid:62), 1 m f : Rn R that map on → to R. The differentiation rules for every f are i i → exactlytheoneswediscussedinSection5.2. (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 150 VectorCalculus Therefore, the partial derivative of a vector-valued function f : Rn Rm withrespecttox R,i = 1,...n,isgivenasthevector → i ∈ ∂f1   lim f1(x1,...,xi−1,xi+h,xi+1,...xn)−f1(x)  ∂ ∂ x f =   ∂x . . . i   =   h→0 . . . h   ∈ Rm. i ∂fm lim fm(x1,...,xi−1,xi+h,xi+1,...xn)−fm(x) ∂xi h→0 h (5.55) From (5.40), we know that the gradient of f with respect to a vector is therowvectorofthepartialderivatives.In(5.55),everypartialderivative ∂f/∂x isacolumnvector.Therefore,weobtainthegradientoff : Rn i Rm withrespecttox Rn bycollectingthesepartialderivatives: → ∈ (cid:20) (cid:21) df(x) = ∂f(x) ∂f(x) (5.56a) dx ∂x 1 ··· ∂x n   ∂f (x) ∂f (x) 1 1  ∂x 1 ··· ∂x n  =   . . . . . .   ∈ Rm×n. (5.56b)    ∂f (x) ∂f (x)  m m ∂x 1 ··· ∂x n Definition 5.6 (Jacobian). The collection of all first-order partial derivaJacobian tivesofavector-valuedfunctionf : Rn Rm iscalledtheJacobian.The → Thegradientofa JacobianJ isanm nmatrix,whichwedefineandarrangeasfollows: × function (cid:20) (cid:21) f :Rn→Rmisa J = f = df(x) = ∂f(x) ∂f(x) (5.57) x matrixofsize ∇ dx ∂x ··· ∂x 1 n m×n.   ∂f (x) ∂f (x) 1 1  ∂x ··· ∂x   1 n  . . =   . . . .   , (5.58)    ∂f m (x) ∂f m (x) ∂x ··· ∂x 1 n   x 1 x =   . . .   , J(i,j) = ∂ ∂ x f i . (5.59) j x n As a special case of (5.58), a function f : Rn R1, which maps a vector x Rn onto a scalar (e.g., f(x) = (cid:80)n x ) → , possesses a Jacobian ∈ i=1 i thatisarowvector(matrixofdimension1 n);see(5.40). × numeratorlayout Remark. In this book, we use the numerator layout of the derivative, i.e., the derivative df/dx of f Rm with respect to x Rn is an m ∈ ∈ × n matrix, where the elements of f define the rows and the elements of x define the columns of the corresponding Jacobian; see (5.58). There Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 5.3 GradientsofVector-ValuedFunctions 151 Figure5.5 The determinantofthe f() Jacobianoff can · b c c beusedtocompute 2 1 2 themagnifier betweentheblue b 1 andorangearea. existsalsothedenominatorlayout,whichisthetransposeofthenumerator denominatorlayout layout.Inthisbook,wewillusethenumeratorlayout. ♦ We will see how the Jacobian is used in the change-of-variable method for probability distributions in Section 6.7. The amount of scaling due to thetransformationofavariableisprovidedbythedeterminant.