withrespecttox. ∂x2 ∂nf isthenthpartialderivativeoff withrespecttox. ∂xn ∂2f = ∂ (cid:0)∂f(cid:1) is the partial derivative obtained by first partial differ- ∂y∂x ∂y ∂x entiatingwithrespecttoxandthenwithrespecttoy. ∂2f is the partial derivative obtained by first partial differentiating by ∂x∂y y andthenx. Hessian TheHessianisthecollectionofallsecond-orderpartialderivatives. Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 5.8 LinearizationandMultivariateTaylorSeries 165 Figure5.12 Linear approximationofa function.The 1 originalfunctionf islinearizedat 0 x0=−2usinga first-orderTaylor seriesexpansion. 1 − 2 − 4 2 0 2 4 − − x )x(f f(x) f(x 0 ) f(x 0 )+f 0 (x 0 )(x x 0 ) − Iff(x,y)isatwice(continuously)differentiablefunction,then ∂2f ∂2f = , (5.146) ∂x∂y ∂y∂x i.e., the order of differentiation does not matter, and the corresponding Hessianmatrix Hessianmatrix  ∂2f ∂2f   ∂x2 ∂x∂y H =   (5.147)  ∂2f ∂2f  ∂x∂y ∂y2 issymmetric.TheHessianisdenotedas 2 f(x,y).Generally,forx Rn and f : Rn R, the Hessian is an n ∇ n x,y matrix. The Hessian mea ∈ sures → × thecurvatureofthefunctionlocallyaround(x,y). Remark (Hessian of a Vector Field). If f : Rn Rm is a vector field, the → Hessianisan(m n n)-tensor. × × ♦ 5.8 Linearization and Multivariate Taylor Series Thegradient f ofafunctionf isoftenusedforalocallylinearapproxi- ∇ mationoff aroundx : 0 f(x) f(x )+( f)(x )(x x ). (5.148) 0 x 0 0 ≈ ∇ − Here ( f)(x ) is the gradient of f with respect to x, evaluated at x . x 0 0 ∇ Figure5.12illustratesthelinearapproximationofafunctionf ataninput x . The original function is approximated by a straight line. This approx0 imation is locally accurate, but the farther we move away from x the 0 worsetheapproximationgets.Equation(5.148)isaspecialcaseofamultivariate Taylor series expansion of f at x , where we consider only the 0 first two terms. We discuss the more general case in the following, which willallowforbetterapproximations. (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 166 VectorCalculus Figure5.13 Visualizingouter products.Outer productsofvectors increasethe dimensionalityof thearrayby1per term.(a)Theouter (a)Givenavectorδ∈R4,weobtaintheouterproductδ2:=δ⊗δ=δδ(cid:62)∈ productoftwo R4×4asamatrix. vectorsresultsina matrix;(b)the outerproductof threevectorsyields athird-ordertensor. (b) An outer product δ3 := δ⊗δ⊗δ ∈ R4×4×4 results in a third-order tensor (“threedimensionalmatrix”),i.e.,anarraywiththreeindexes. Definition 5.7 (MultivariateTaylorSeries). Weconsiderafunction f : RD R (5.149) → x f(x), x RD, (5.150) (cid:55)→ ∈ that is smooth at x . When we define the difference vector δ := x x , 0 0 − multivariateTaylor themultivariateTaylorseriesoff at(x 0 )isdefinedas series f(x) = (cid:88) ∞ D x kf(x 0 ) δk, (5.151) k! k=0 where Dkf(x ) is the k-th (total) derivative of f with respect to x, evalx 0 uatedatx . 0 Taylorpolynomial Definition 5.8 (TaylorPolynomial). TheTaylorpolynomialofdegreenof f atx containsthefirstn+1componentsoftheseriesin(5.151)andis 0 definedas T (x) = (cid:88) n D x kf(x 0 ) δk. (5.152) n k! k=0 In (5.151) and (5.152), we used the slightly sloppy notation of δk, which is not defined for vectors x RD, D > 1, and k > 1. Note that Avectorcanbe both Dkf and δk are k-th order te ∈ nsors, i.e., k-dimensional arrays. The x implementedasa ktimes one-dimensional kth-order tensor δk R (cid:122) D×D (cid:125) × (cid:124) ...×D (cid:123) is obtained as a k-fold outer product, a tw rr o a - y d , i a m m en a s t i r o ix