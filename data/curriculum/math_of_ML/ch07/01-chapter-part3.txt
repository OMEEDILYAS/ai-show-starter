− − to obtain a sequence of estimates that converge to the minimum value Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 7.1 OptimizationUsingGradientDescent 229 2 Figure7.3 Gradient descentona two-dimensional quadraticsurface 1 (shownasa heatmap).See Example7.1fora 0 description. 1 − 2 − 4 2 0 2 4 − − x 1 x 2 90 50.0 40.0 75 60 0.0 45 30 15 10.0 80. 7 0 0.0 60.0 50.0 30.0 40.0 20.0 0 15 − (illustrated in Figure 7.3). We can see (both from the figure and by pluggingx into(7.8)withγ = 0.085)thatthenegativegradientatx points 0 0 north and east, leading to x = [ 1.98,1.21](cid:62). Repeating that argument 1 − givesusx = [ 1.32, 0.42](cid:62),andsoon. 2 − − Remark. Gradient descent can be relatively slow close to the minimum: Its asymptotic rate of convergence is inferior to many other methods. Usingtheballrollingdownthehillanalogy,whenthesurfaceisalong,thin valley, the problem is poorly conditioned (Trefethen and Bau III, 1997). For poorly conditioned convex problems, gradient descent increasingly “zigzags” as the gradients point nearly orthogonally to the shortest directiontoaminimumpoint;seeFigure7.3. ♦ 7.1.1 Step-size As mentioned earlier, choosing a good step-size is important in gradient descent. If the step-size is too small, gradient descent can be slow. If the Thestep-sizeisalso step-size is chosen too large, gradient descent can overshoot, fail to con- calledthelearning rate. verge, or even diverge. We will discuss the use of momentum in the next section. It is a method that smoothes out erratic behavior of gradient updatesanddampensoscillations. Adaptive gradient methods rescale the step-size at each iteration, depending on local properties of the function. There are two simple heuristics(Toussaint,2012): When the function value increases after a gradient step, the step-size wastoolarge.Undothestepanddecreasethestep-size. Whenthefunctionvaluedecreasesthestepcouldhavebeenlarger.Try toincreasethestep-size. (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 230 ContinuousOptimization Although the “undo” step seems to be a waste of resources, using this heuristicguaranteesmonotonicconvergence. Example 7.2 (Solving a Linear Equation System) WhenwesolvelinearequationsoftheformAx = b,inpracticewesolve Ax b = 0approximatelybyfindingx thatminimizesthesquarederror ∗ − Ax b 2 = (Ax b)(cid:62)(Ax b) (7.9) (cid:107) − (cid:107) − − ifweusetheEuclideannorm.Thegradientof(7.9)withrespecttoxis = 2(Ax b)(cid:62)A. (7.10) x ∇ − We can use this gradient directly in a gradient descent algorithm. However, for this particular special case, it turns out that there is an analytic solution, which can be found by setting the gradient to zero. We will see moreonsolvingsquarederrorproblemsinChapter9. Remark. WhenappliedtothesolutionoflinearsystemsofequationsAx = b,gradientdescentmayconvergeslowly.Thespeedofconvergenceofgraconditionnumber dient descent is dependent on the condition number κ = σ(A)max, which σ(A)min is the ratio of the maximum to the minimum singular value (Section 4.5) of A. The condition number essentially measures the ratio of the most curved direction versus the least curved direction, which corresponds to ourimagerythatpoorlyconditionedproblemsarelong,thinvalleys:They are very curved in one direction, but very flat in the other. Instead of directlysolvingAx = b,onecouldinsteadsolveP−1(Ax b) = 0,where preconditioner P iscalledthepreconditioner.ThegoalistodesignP−1− suchthatP−1A has a better condition number, but at the same time P−1 is easy to compute. For further information on gradient descent, preconditioning, and convergencewerefertoBoydandVandenberghe(2004,chapter9). ♦ 7.1.2 Gradient Descent With Momentum As illustrated in Figure 7.3, the convergence of gradient descent may be very slow if the curvature of the optimization surface is such that there areregionsthatarepoorlyscaled.Thecurvatureissuchthatthegradient descent steps hops between the