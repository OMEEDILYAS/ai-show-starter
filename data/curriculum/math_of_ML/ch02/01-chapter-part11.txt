 0 0 0 1 4 − 0 0 0 0 1 − Fromthisform,wecanimmediatelyreadoutthesolutionsofAx = 0by takingthecolumnsofA˜,whichcontain 1onthediagonal: −       3 3        1  0     x R5 : x = λ 1   − 0  +λ 2   9   , λ 1 ,λ 2 R  , (2.55)    ∈   0     4   ∈      0 − 1   − whichisidenticaltothesolutionin(2.50)thatweobtainedby“insight”. Calculating the Inverse To compute the inverse A−1 of A Rn×n, we need to find a matrix X that satisfies AX = I . Then, X ∈ = A−1. We can write this down as n a set of simultaneous linear equations AX = I , where we solve for n X = [x x ]. We use the augmented matrix notation for a compact 1 n |···| representationofthissetofsystemsoflinearequationsandobtain (cid:2) A I (cid:3) (cid:32) (cid:32) (cid:2) I A−1(cid:3) . (2.56) n n | ··· | This means that if we bring the augmented equation system into reduced row-echelon form, we can read out the inverse on the right-hand side of theequationsystem.Hence,determiningtheinverseofamatrixisequivalenttosolvingsystemsoflinearequations. (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 34 LinearAlgebra Example2.9(CalculatinganInverseMatrixbyGaussianElimination) Todeterminetheinverseof   1 0 2 0 1 1 0 0 A =   (2.57) 1 2 0 1 1 1 1 1 wewritedowntheaugmentedmatrix   1 0 2 0 1 0 0 0  1 1 0 0 0 1 0 0     1 2 0 1 0 0 1 0  1 1 1 1 0 0 0 1 anduseGaussianeliminationtobringitintoreducedrow-echelonform   1 0 0 0 1 2 2 2 − −  0 1 0 0 1 1 2 2  − − ,  0 0 1 0 1 1 1 1 − − 0 0 0 1 1 0 1 2 − − suchthatthedesiredinverseisgivenasitsright-handside:   1 2 2 2 − − A−1 =   1 − 1 2 − 2  . (2.58)  1 1 1 1 − − 1 0 1 2 − − We can verify that (2.58) is indeed the inverse by performing the multiplicationAA−1 andobservingthatwerecoverI . 4 2.3.4 Algorithms for Solving a System of Linear Equations In the following, we briefly discuss approaches to solving a system of linear equations of the form Ax = b. We make the assumption that a solutionexists.Shouldtherebenosolution,weneedtoresorttoapproximate solutions,whichwedonotcoverinthischapter.Onewaytosolvetheapproximate problem is using the approach of linear regression, which we discussindetailinChapter9. In special cases, we may be able to determine the inverse A−1, such that the solution of Ax = b is given as x = A−1b. However, this is onlypossibleifAisasquarematrixandinvertible,whichisoftennotthe case. Otherwise, under mild assumptions (i.e., A needs to have linearly independentcolumns)wecanusethetransformation Ax = b A(cid:62)Ax = A(cid:62)b x = (A(cid:62)A)−1A(cid:62)b (2.59) ⇐⇒ ⇐⇒ Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 2.4 VectorSpaces 35 and use the Moore-Penrose pseudo-inverse (A(cid:62)A)−1A(cid:62) to determine the Moore-Penrose solution (2.59) that solves Ax = b, which also corresponds