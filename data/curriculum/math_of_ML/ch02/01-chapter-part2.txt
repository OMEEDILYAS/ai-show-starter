kind of vector and Rn. When it is convenient, we will use courseonlinear algebra: intuitionsaboutgeometricvectorsandconsiderarray-basedalgorithms. http://tinyurl. Onemajorideainmathematicsistheideaof“closure”.Thisisthequescom/29p5q8j tion: What is the set of all things that can result from my proposed oper3Blue1Brownseries ations?Inthecaseofvectors:Whatisthesetofvectorsthatcanresultby onlinearalgebra: starting with a small set of vectors, and adding them to each other and https://tinyurl. com/h5g4kps scaling them? This results in a vector space (Section 2.4). The concept of a vector space and its properties underlie much of machine learning. The conceptsintroducedinthischapteraresummarizedinFigure2.2. ThischapterismostlybasedonthelecturenotesandbooksbyDrumm and Weil (2001), Strang (2003), Hogben (2013), Liesen and Mehrmann (2015), as well as Pavel Grinfeld’s Linear Algebra series. Other excellent Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 2.1 SystemsofLinearEquations 19 Figure2.2 Amind Vector mapoftheconcepts mposes introducedinthis co chapter,alongwith wheretheyareused Chapter5 Vectorcalculus Matrix inotherpartsofthe Vectorspace Group inde L p i e n n e d ar ence book. Systemof linearequations Linear/affine mapping Basis Matrix inverse Gaussian elimination Chapter3 Chapter12 Chapter10 Analyticgeometry Classification Dimensionality reduction closure Abelian represents re p re se with+ n ts solvedby propertyof solves maximalset resourcesareGilbertStrang’sLinearAlgebracourseatMITandtheLinear AlgebraSeriesby3Blue1Brown. Linear algebra plays an important role in machine learning and general mathematics. The concepts introduced in this chapter are further expanded to include the idea of geometry in Chapter 3. In Chapter 5, we will discuss vector calculus, where a principled knowledge of matrix operations is essential. In Chapter 10, we will use projections (to be introduced in Section 3.8) for dimensionality reduction with principal componentanalysis(PCA).InChapter9,wewilldiscusslinearregression,where linearalgebraplaysacentralroleforsolvingleast-squaresproblems. 2.1 Systems of Linear Equations Systems of linear equations play a central part of linear algebra. Many problems can be formulated as systems of linear equations, and linear algebragivesusthetoolsforsolvingthem. Example 2.1 A company produces products N ,...,N for which resources 1 n R ,...,R are required. To produce a unit of product N , a units of 1 m j ij resourceR areneeded,wherei = 1,...,mandj = 1,...,n. i The objective is to find an optimal production plan, i.e., a plan of how many units x of product N should be produced if a total of b units of j j i resourceR areavailableand(ideally)noresourcesareleftover. i If we produce x ,...,x units of the corresponding products, we need 1 n (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 20 LinearAlgebra atotalof a x + +a x (2.2) i1 1 in n ··· manyunitsofresourceR .Anoptimalproductionplan(x ,...,x ) Rn, i 1 n ∈ therefore,hastosatisfythefollowingsystemofequations: a x + +a x = b 11 1 1n n 1 ··· . . . , (2.3) a x + +a x = b m1 1 mn n m ··· wherea Randb R. ij i ∈ ∈ systemoflinear Equation (2.3) is the general form of a system of linear equations, and equations x ,...,x are the unknowns of this system. Every n-tuple (x ,...,x ) 1 n 1 n solution Rn thatsatisfies(2.3)isasolutionofthelinearequationsystem. ∈ Example 2.2 Thesystemoflinearequations x + x + x = 3 (1) 1 2 3 x x + 2x = 2 (2) (2.4) 1 2 3 − 2x + 3x = 1 (3) 1 3 hasnosolution:Addingthefirsttwoequationsyields2x +3x = 5,which 1 3 contradictsthethirdequation(3). Letushavealookatthesystemoflinearequations x + x + x = 3 (1) 1 2 3 x x