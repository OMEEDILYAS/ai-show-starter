to the mini- pseudo-inverse mumnormleast-squaressolution.Adisadvantageofthisapproachisthat itrequiresmanycomputationsforthematrix-matrixproductandcomputing the inverse of A(cid:62)A. Moreover, for reasons of numerical precision it is generally not recommended to compute the inverse or pseudo-inverse. In the following, we therefore briefly discuss alternative approaches to solvingsystemsoflinearequations. Gaussian elimination plays an important role when computing determinants (Section 4.1), checking whether a set of vectors is linearly independent(Section2.5),computingtheinverseofamatrix(Section2.2.2), computing the rank of a matrix (Section 2.6.2), and determining a basis ofavectorspace(Section2.6.1).Gaussianeliminationisanintuitiveand constructive way to solve a system of linear equations with thousands of variables. However, for systems with millions of variables, it is impracticalastherequirednumberofarithmeticoperationsscalescubicallyinthe numberofsimultaneousequations. Inpractice,systemsofmanylinearequationsaresolvedindirectly,byeitherstationaryiterativemethods,suchastheRichardsonmethod,theJacobimethod,theGauß-Seidelmethod,andthesuccessiveover-relaxation method,orKrylovsubspacemethods,suchasconjugategradients,generalized minimal residual, or biconjugate gradients. We refer to the books byStoerandBurlirsch(2002),Strang(2003),andLiesenandMehrmann (2015)forfurtherdetails. Letx beasolutionofAx = b.Thekeyideaoftheseiterativemethods ∗ istosetupaniterationoftheform x(k+1) = Cx(k)+d (2.60) forsuitableC anddthatreducestheresidualerror x(k+1) x inevery ∗ (cid:107) − (cid:107) iterationandconvergestox .Wewillintroducenorms ,whichallow ∗ (cid:107)·(cid:107) ustocomputesimilaritiesbetweenvectors,inSection3.1. 2.4 Vector Spaces Thus far, we have looked at systems of linear equations and how to solve them (Section 2.3). We saw that systems of linear equations can be compactly represented using matrix-vector notation (2.10). In the following, wewillhaveacloserlookatvectorspaces,i.e.,astructuredspaceinwhich vectorslive. Inthebeginningofthischapter,weinformallycharacterizedvectorsas objects that can be added together and multiplied by a scalar, and they remain objects of the same type. Now, we are ready to formalize this, and we will start by introducing the concept of a group, which is a set of elements and an operation defined on these elements that keeps some structureofthesetintact. (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 36 LinearAlgebra 2.4.1 Groups Groups play an important role in computer science. Besides providing a fundamental framework for operations on sets, they are heavily used in cryptography,codingtheory,andgraphics. Definition2.7(Group). Consideraset andanoperation : G ⊗ G×G → G group definedon .ThenG := ( , )iscalledagroupifthefollowinghold: G G ⊗ closure 1. Closureof under : x,y : x y associativity G ⊗ ∀ ∈ G ⊗ ∈ G 2. Associativity: x,y,z : (x y) z = x (y z) neutralelement ∀ ∈ G ⊗ ⊗ ⊗ ⊗ 3. Neutralelement: e x : x e = xande x = x inverseelement ∃ ∈ G∀ ∈ G ⊗ ⊗ 4. Inverse element: x y : x y = e and y x = e. We often ∀ ∈ G∃ ∈ G ⊗ ⊗ writex−1 todenotetheinverseelementofx. Remark. The inverse element is defined with respect to the operation ⊗ anddoesnotnecessarilymean 1. x ♦ Abeliangroup If additionally x,y : x y = y x, then G = ( , ) is an Abelian ∀ ∈ G ⊗ ⊗ G ⊗ group(commutative). Example 2.10 (Groups) Let us have a look at some examples of sets with associated operations andseewhethertheyaregroups: (Z,+)isagroup. N 0:=N∪{0} (N 0 ,+) is not a group: Although (N 0 ,+) possesses a neutral element (0),theinverseelementsaremissing. (Z, )isnotagroup:Although(Z, )containsaneutralelement(1),the inve · rseelementsforanyz Z,z = · 1,aremissing. (R, )isnotagroupsince0 ∈ doesn (cid:54) ot ± possessaninverseelement. (R · 0 , )isAbelian. (R\ n, { + } ), · (Zn,+),n NareAbelianif+isdefinedcomponentwise,i.e., ∈ (x , ,x )+(y , ,y ) = (x +y , ,x +y ). (2.61) 1 n 1 n 1 1 n n ··· ··· ··· Then, (x ,