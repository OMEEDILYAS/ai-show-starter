tells us something about the relationship between the random variables: cdependsdirectlyonaandb. bdependsdirectlyona. adependsneitheronbnoronc. For the factorization in (8.29), we obtain the directed graphical model in Figure8.9(a). Ingeneral,wecanconstructthecorrespondingdirectedgraphicalmodel fromafactorizedjointdistributionasfollows: 1. Createanodeforallrandomvariables. 2. For each conditional distribution, we add a directed link (arrow) to the graph from the nodes corresponding to the variables on which the distributionisconditioned. Thegraphlayout The graph layout depends on the choice of factorization of the joint dis- dependsonthe factorizationofthe tribution. jointdistribution. We discussed how to get from a known factorization of the joint distribution to the corresponding directed graphical model. Now, we will do (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 280 WhenModelsMeetData exactly the opposite and describe how to extract the joint distribution of asetofrandomvariablesfromagivengraphicalmodel. Example 8.8 Looking at the graphical model in Figure 8.9(b), we exploit two properties: The joint distribution p(x ,...,x ) we seek is the product of a set of 1 5 conditionals,oneforeachnodeinthegraph.Inthisparticularexample, wewillneedfiveconditionals. Each conditional depends only on the parents of the corresponding nodeinthegraph.Forexample,x willbeconditionedonx . 4 2 These two properties yield the desired factorization of the joint distribution p(x ,x ,x ,x ,x ) = p(x )p(x )p(x x )p(x x ,x )p(x x ). (8.30) 1 2 3 4 5 1 5 2 5 3 1 2 4 2 | | | Ingeneral,thejointdistributionp(x) = p(x ,...,x )isgivenas 1 K K (cid:89) p(x) = p(x Pa ), (8.31) k k | k=1 where Pa means “the parent nodes of x ”. Parent nodes of x are nodes k k k thathavearrowspointingtox . k We conclude this subsection with a concrete example of the coin-flip experiment. Consider a Bernoulli experiment (Example 6.8) where the probabilitythattheoutcomexofthisexperimentis“heads”is p(x µ) = Ber(µ). (8.32) | WenowrepeatthisexperimentN timesandobserveoutcomesx ,...,x 1 N sothatweobtainthejointdistribution N (cid:89) p(x ,...,x µ) = p(x µ). (8.33) 1 N n | | n=1 The expression on the right-hand side is a product of Bernoulli distributions on each individual outcome because the experiments are independent. Recall from Section 6.4.5 that statistical independence means that thedistributionfactorizes.Towritethegraphicalmodeldownforthissetting, we make the distinction between unobserved/latent variables and observedvariables.Graphically,observedvariablesaredenotedbyshaded nodes so that we obtain the graphical model in Figure 8.10(a). We see that the single parameter µ is the same for all x , n = 1,...,N as the n outcomes x are identically distributed. A more compact, but equivalent, n graphical model for this setting is given in Figure 8.10(b), where we use Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 8.5 DirectedGraphicalModels 281 Figure8.10 µ α µ β Graphicalmodels µ forarepeated Bernoulli x x experiment. n n x x 1 N n=1,...,N n=1,...,N (a)Versionwithxnexplicit. (b) Version with (c) Hyperparameters α platenotation. andβonthelatentµ. theplatenotation.Theplate(box)repeatseverythinginside(inthiscase, plate theobservationsx )N times.Therefore,bothgraphicalmodelsareequivn alent, but the plate notation is more compact. Graphical models immediately allow us to place a hyperprior on µ. A hyperprior is a second layer hyperprior of prior distributions on the parameters of the first layer of priors. Figure 8.10(c) places a Beta(α,β) prior on the latent variable µ. If we treat α and β as deterministic parameters, i.e., not random variables, we omit thecirclearoundit. 8.5.2 Conditional Independence and d-Separation Directedgraphicalmodelsallowustofindconditionalindependence(Section6.4.5)relationshippropertiesofthejointdistributiononlybylooking atthegraph.Aconceptcalledd-separation(Pearl,1988)iskeytothis. d-separation