Considerageneraldirectedgraphinwhich , , arearbitrarynoninA B C tersecting sets of nodes (whose union may be smaller than the complete setofnodesinthegraph).Wewishtoascertainwhetheraparticularconditional independence statement, “ is conditionally independent of A B given ”,denotedby C , (8.34) A ⊥⊥ B|C is implied by a given directed acyclic graph. To do so, we consider all possible trails (paths that ignore the direction of the arrows) from any node in to any nodes in . Any such path is said to be blocked if it A B includesanynodesuchthateitherofthefollowingaretrue: The arrows on the path meet either head to tail or tail to tail at the node,andthenodeisintheset . C The arrows meet head to head at the node, and neither the node nor anyofitsdescendantsisintheset . C If all paths are blocked, then is said to be d-separated from by , A B C andthejointdistributionoverallofthevariablesinthegraphwillsatisfy . A ⊥⊥ B|C (cid:13)c2019M.P.Deisenroth,A.A.Faisal,C.S.Ong.TobepublishedbyCambridgeUniversityPress. 282 WhenModelsMeetData Figure8.12 Three typesofgraphical a b a b a b models:(a)Directed graphicalmodels (Bayesian networks); c c c (b)Undirected graphicalmodels (a)Directedgraphicalmodel (b) Undirected graphical (c)Factorgraph (Markovrandom model fields);(c)Factor graphs. Example 8.9 (Conditional Independence) Figure8.11 a b c D-separation example. d e ConsiderthegraphicalmodelinFigure8.11.Visualinspectiongivesus b d a,c (8.35) ⊥⊥ | a c b (8.36) ⊥⊥ | b d c (8.37) ⊥(cid:54)⊥ | a c b,e (8.38) ⊥(cid:54)⊥ | Directed graphical models allow a compact representation of probabilistic models, and we will see examples of directed graphical models in Chapters9,10,and11.Therepresentation,alongwiththeconceptofconditional independence, allows us to factorize the respective probabilistic modelsintoexpressionsthatareeasiertooptimize. The graphical representation of the probabilistic model allows us to visually see the impact of design choices we have made on the structure of the model. We often need to make high-level assumptions about the structure of the model. These modeling assumptions (hyperparameters) affect the prediction performance, but cannot be selected directly using the approaches we have seen so far. We will discuss different ways to choosethestructureinSection8.6. Draft(2019-12-11)of“MathematicsforMachineLearning”.Feedback:https://mml-book.com. 8.6 ModelSelection 283 8.5.3 Further Reading An introduction to probabilistic graphical models can be found in Bishop (2006, chapter 8), and an extensive description of the different applicationsandcorrespondingalgorithmicimplicationscanbefoundinthebook byKollerandFriedman(2009).Therearethreemaintypesofprobabilistic graphicalmodels: directedgraphical Directedgraphicalmodels(Bayesiannetworks);seeFigure8.12(a) model Undirectedgraphicalmodels(Markovrandomfields);seeFigure8.12(b) Bayesiannetwork Factorgraphs;seeFigure8.12(c) undirectedgraphical model Graphical models allow for graph-based algorithms for inference and Markovrandom learning, e.g., via local message passing. Applications range from rank- field factorgraph ing in online games (Herbrich et al., 2007) and computer vision (e.g., image segmentation, semantic labeling, image denoising, image restoration (Kittler and Fo¨glein, 1984; Sucar and Gillies, 1994; Shotton et al., 2006;Szeliskietal.,2008))tocodingtheory(McElieceetal.,1998),solving linear equation systems (Shental et al., 2008), and iterative Bayesian stateestimationinsignalprocessing(Bicksonetal.,2007;Deisenrothand Mohamed,2012). One topic that is particularly important in real applications that we do not discuss in this book is the idea of structured prediction (Bakir et al., 2007; Nowozin et al., 2014), which allows machine learning models to tackle predictions that are structured, for example sequences, trees, and graphs. The popularity of neural network models has allowed more flexible probabilistic models to be used, resulting in many useful applicationsofstructuredmodels(Goodfellowetal.,2016,chapter16).Inrecent years, there has been a renewed interest in graphical models due to their applications to causal inference (Pearl, 2009; Imbens and Rubin, 2015;